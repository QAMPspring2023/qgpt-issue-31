{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR7DHQg4yCjB",
        "outputId": "c80ad887-eba9-49e8-a896-99d40b91c49f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.30.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.24 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.10.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.1)\n",
            "Collecting rustworkx (from pennylane)\n",
            "  Downloading rustworkx-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.5)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Collecting semantic-version>=2.7 (from pennylane)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting autoray>=0.3.1 (from pennylane)\n",
            "  Downloading autoray-0.6.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.3.0)\n",
            "Collecting pennylane-lightning>=0.30 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.30.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.27.1)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd->pennylane) (0.18.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4)\n",
            "Installing collected packages: semantic-version, rustworkx, autoray, pennylane-lightning, pennylane\n",
            "Successfully installed autoray-0.6.3 pennylane-0.30.0 pennylane-lightning-0.30.0 rustworkx-0.12.1 semantic-version-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "ZVOr3qrBxLf_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJFXlAK4xOLX",
        "outputId": "f6464b7f-5cc7-42b6-aba3-d981d39d819c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/gdrive/MyDrive/New_test/'"
      ],
      "metadata": {
        "id": "9ff6G469xQej"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "vocab_size = 1000\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "class_names = [\"Negative\", \"Positive\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "616pEXSgoD6O",
        "outputId": "215d8197-bf0b-45ab-9cd9-1a75372ffdb4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select dataset evenly \n",
        "selected_num=128\n",
        "\n",
        "new_x_train=[]\n",
        "new_y_train=[]\n",
        "indx=0\n",
        "while len(new_x_train) < selected_num:\n",
        "    if len(x_train[indx]) <= 200:\n",
        "        sum_y=np.sum(new_y_train)\n",
        "        len_y=len(new_y_train)\n",
        "        if sum_y >= selected_num//2:\n",
        "            if y_train[indx]==0:\n",
        "                new_x_train.append(x_train[indx])\n",
        "                new_y_train.append(y_train[indx])\n",
        "                indx+=1\n",
        "            else:\n",
        "                indx+=1\n",
        "                continue\n",
        "        elif ((len_y-sum_y) >= selected_num//2):\n",
        "            if y_train[indx]==1:\n",
        "                new_x_train.append(x_train[indx])\n",
        "                new_y_train.append(y_train[indx])\n",
        "                indx+=1\n",
        "            else:\n",
        "                indx+=1\n",
        "                continue\n",
        "        else:\n",
        "            new_x_train.append(x_train[indx])\n",
        "            new_y_train.append(y_train[indx])\n",
        "            indx+=1\n",
        "    else:\n",
        "        indx+=1\n",
        "\n",
        "selected_num=128\n",
        "\n",
        "new_x_test=[]\n",
        "new_y_test=[]\n",
        "indx=0\n",
        "while len(new_x_test) < selected_num:\n",
        "    if len(x_test[indx]) <= 200:\n",
        "        sum_y=np.sum(new_y_test)\n",
        "        len_y=len(new_y_test)\n",
        "        if sum_y >= selected_num//2:\n",
        "            if y_test[indx]==0:\n",
        "                new_x_test.append(x_test[indx])\n",
        "                new_y_test.append(y_test[indx])\n",
        "                indx+=1\n",
        "            else:\n",
        "                indx+=1\n",
        "                continue\n",
        "        elif ((len_y-sum_y) >= selected_num//2):\n",
        "            if y_test[indx]==1:\n",
        "                new_x_test.append(x_test[indx])\n",
        "                new_y_test.append(y_test[indx])\n",
        "                indx+=1\n",
        "            else:\n",
        "                indx+=1\n",
        "                continue\n",
        "        else:\n",
        "            new_x_test.append(x_test[indx])\n",
        "            new_y_test.append(y_test[indx])\n",
        "            indx+=1\n",
        "    else:\n",
        "        indx+=1"
      ],
      "metadata": {
        "id": "rBELLV-ooWyi"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.array(new_x_train)#[:128]\n",
        "y_train=np.array(new_y_train)#[:128]\n",
        "\n",
        "x_test=np.array(new_x_test)#[:128]\n",
        "y_test=np.array(new_y_test)#[:128]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qN9RXBAkopEn",
        "outputId": "f71f3a7b-ef38-435c-98fd-fc26e52e6926"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-b98d59874a29>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_train=np.array(new_x_train)#[:128]\n",
            "<ipython-input-30-b98d59874a29>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_test=np.array(new_x_test)#[:128]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the word index from the dataset\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "\n",
        "# Ensure that \"special\" words are mapped into human readable terms \n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNKNOWN>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "# Perform reverse word lookup and make it callable\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvHYhW60otea",
        "outputId": "2efbb219-f7e3-494a-cfc9-52f178fc10b5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatonate test and training datasets\n",
        "allreviews = np.concatenate((x_train, x_test), axis=0)\n",
        "\n",
        "# Review lengths across test and training whole datasets\n",
        "print(\"Maximum review length: {}\".format(len(max((allreviews), key=len))))\n",
        "print(\"Minimum review length: {}\".format(len(min((allreviews), key=len))))\n",
        "result = [len(x) for x in allreviews]\n",
        "print(\"Mean review length: {}\".format(np.mean(result)))\n",
        "\n",
        "# Print a review and it's class as stored in the dataset. Replace the number\n",
        "# to select a different review.\n",
        "print(\"\")\n",
        "print(\"Machine readable Review\")\n",
        "print(\"  Review Text: \" + str(x_train[60]))\n",
        "print(\"  Review Sentiment: \" + str(y_train[60]))\n",
        "\n",
        "# Print a review and it's class in human readable format. Replace the number\n",
        "# to select a different review.\n",
        "print(\"\")\n",
        "print(\"Human Readable Review\")\n",
        "print(\"  Review Text: \" + decode_review(x_train[0]))\n",
        "print(\"  Review Sentiment: \" + class_names[y_train[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBjeJRvWoxQR",
        "outputId": "3c1ce30d-eae8-4e37-99e5-62297fc4c04f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum review length: 200\n",
            "Minimum review length: 19\n",
            "Mean review length: 132.546875\n",
            "\n",
            "Machine readable Review\n",
            "  Review Text: [1, 13, 244, 6, 666, 337, 7, 2, 2, 5, 28, 296, 958, 7, 27, 102, 366, 150, 5, 600, 7, 98, 28, 2, 8, 97, 72, 462, 2, 122, 89, 8, 2, 369, 5, 2, 84, 10, 10, 14, 20, 9, 2, 44, 6, 132, 52, 17, 2, 84, 125, 190, 29, 47, 35, 2, 270, 7, 2, 15, 2, 90, 39, 399, 183, 15, 238, 43, 97, 90, 804, 21, 11, 4, 130, 29, 630, 56, 399, 98, 4, 2, 7, 113, 10, 10, 4, 20, 9, 73, 2, 19, 486, 883, 52, 116, 5, 82, 6, 227, 7, 6, 2, 837, 94, 31, 7, 148, 102, 121, 25, 100, 43, 30, 654, 54, 12, 630]\n",
            "  Review Sentiment: 1\n",
            "\n",
            "Human Readable Review\n",
            "  Review Text: <START> big <UNKNOWN> big <UNKNOWN> bad music and a <UNKNOWN> <UNKNOWN> <UNKNOWN> these are the words to best <UNKNOWN> this terrible movie i love cheesy horror movies and i've seen <UNKNOWN> but this had got to be on of the worst ever made the plot is <UNKNOWN> <UNKNOWN> and ridiculous the acting is an <UNKNOWN> the script is completely <UNKNOWN> the best is the end <UNKNOWN> with the <UNKNOWN> and how he worked out who the killer is it's just so <UNKNOWN> <UNKNOWN> written the <UNKNOWN> are <UNKNOWN> and funny in <UNKNOWN> <UNKNOWN> the <UNKNOWN> is big lots of <UNKNOWN> <UNKNOWN> men <UNKNOWN> those cut <UNKNOWN> <UNKNOWN> that show off their <UNKNOWN> <UNKNOWN> that men actually <UNKNOWN> them and the music is just <UNKNOWN> <UNKNOWN> that plays over and over again in almost every scene there is <UNKNOWN> music <UNKNOWN> and <UNKNOWN> taking away <UNKNOWN> and the <UNKNOWN> still doesn't close for <UNKNOWN> all <UNKNOWN> <UNKNOWN> this is a truly bad film whose only <UNKNOWN> is to look back on the <UNKNOWN> that was the <UNKNOWN> and have a good old laugh at how bad everything was back then\n",
            "  Review Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The length of reviews\n",
        "review_length = 200\n",
        "\n",
        "# Padding / truncated our reviews\n",
        "x_train = sequence.pad_sequences(x_train, maxlen = review_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen = review_length)\n",
        "\n",
        "# Check the size of our datasets. Review data for both test and training should \n",
        "# contain 25000 reviews of 500 integers. Class data should contain 25000 values, \n",
        "# one for each review. Class values are 0 or 1, indicating a negative \n",
        "# or positive review.\n",
        "print(\"Shape Training Review Data: \" + str(x_train.shape))\n",
        "print(\"Shape Training Class Data: \" + str(np.shape(y_train)))\n",
        "print(\"Shape Test Review Data: \" + str(x_test.shape))\n",
        "print(\"Shape Test Class Data: \" + str(y_test.shape))\n",
        "\n",
        "# Note padding is added to start of review, not the end\n",
        "print(\"\")\n",
        "print(\"Human Readable Review Text (post padding): \" + decode_review(x_train[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPQgTb5Qo1yJ",
        "outputId": "d3ee92c3-072d-4d6a-f933-828706f0f3fc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape Training Review Data: (128, 200)\n",
            "Shape Training Class Data: (128,)\n",
            "Shape Test Review Data: (128, 200)\n",
            "Shape Test Class Data: (128,)\n",
            "\n",
            "Human Readable Review Text (post padding): <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> big <UNKNOWN> big <UNKNOWN> bad music and a <UNKNOWN> <UNKNOWN> <UNKNOWN> these are the words to best <UNKNOWN> this terrible movie i love cheesy horror movies and i've seen <UNKNOWN> but this had got to be on of the worst ever made the plot is <UNKNOWN> <UNKNOWN> and ridiculous the acting is an <UNKNOWN> the script is completely <UNKNOWN> the best is the end <UNKNOWN> with the <UNKNOWN> and how he worked out who the killer is it's just so <UNKNOWN> <UNKNOWN> written the <UNKNOWN> are <UNKNOWN> and funny in <UNKNOWN> <UNKNOWN> the <UNKNOWN> is big lots of <UNKNOWN> <UNKNOWN> men <UNKNOWN> those cut <UNKNOWN> <UNKNOWN> that show off their <UNKNOWN> <UNKNOWN> that men actually <UNKNOWN> them and the music is just <UNKNOWN> <UNKNOWN> that plays over and over again in almost every scene there is <UNKNOWN> music <UNKNOWN> and <UNKNOWN> taking away <UNKNOWN> and the <UNKNOWN> still doesn't close for <UNKNOWN> all <UNKNOWN> <UNKNOWN> this is a truly bad film whose only <UNKNOWN> is to look back on the <UNKNOWN> that was the <UNKNOWN> and have a good old laugh at how bad everything was back then\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_X_train=[]\n",
        "for seq in x_train:\n",
        "    a=torch.tensor(np.pi*(seq/1000-0.5))\n",
        "    new_X_train.append(torch.reshape(a, (10, 20)))\n",
        "\n",
        "new_y_train=[]\n",
        "for seq in y_train:\n",
        "    new_y_train.append(torch.tensor(seq))"
      ],
      "metadata": {
        "id": "wPwcyzdxo5tn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_X_train=torch.stack(new_X_train)\n",
        "\n",
        "label=torch.stack(new_y_train)"
      ],
      "metadata": {
        "id": "MT6EG9nro71z"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_X_test=[]\n",
        "for seq in x_test:\n",
        "    a=torch.tensor(np.pi*(seq/1000-0.5))\n",
        "    new_X_test.append(torch.reshape(a, (10, 20)))\n",
        "\n",
        "new_y_test=[]\n",
        "for seq in y_test:\n",
        "    new_y_test.append(torch.tensor(seq))"
      ],
      "metadata": {
        "id": "iWRAhptvo_X5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import inspect\n",
        "import math\n",
        "from collections.abc import Iterable\n",
        "from typing import Callable, Dict, Union, Any\n",
        "\n",
        "from pennylane.qnode import QNode\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    from torch.nn import Module\n",
        "\n",
        "    TORCH_IMPORTED = True\n",
        "except ImportError:\n",
        "    # The following allows this module to be imported even if PyTorch is not installed. Users\n",
        "    # will instead see an ImportError when instantiating the TorchLayer.\n",
        "    from unittest.mock import Mock\n",
        "\n",
        "    Module = Mock\n",
        "    TORCH_IMPORTED = False\n",
        "\n",
        "\n",
        "class TorchLayer(Module):\n",
        "    def __init__(self,qnode,weights):\n",
        "        if not TORCH_IMPORTED:\n",
        "            raise ImportError(\n",
        "                \"TorchLayer requires PyTorch. PyTorch can be installed using:\\n\"\n",
        "                \"pip install torch\\nAlternatively, \"\n",
        "                \"visit https://pytorch.org/get-started/locally/ for detailed \"\n",
        "                \"instructions.\"\n",
        "            )\n",
        "        super().__init__()\n",
        "\n",
        "        #weight_shapes = {\n",
        "        #    weight: (tuple(size) if isinstance(size, Iterable) else () if size == 1 else (size,))\n",
        "        #    for weight, size in weight_shapes.items()\n",
        "        #}\n",
        "\n",
        "        # validate the QNode signature, and convert to a Torch QNode.\n",
        "        # TODO: update the docstring regarding changes to restrictions when tape mode is default.\n",
        "        #self._signature_validation(qnode, weight_shapes)\n",
        "        self.qnode = qnode\n",
        "        self.qnode.interface = \"torch\"\n",
        "\n",
        "        self.qnode_weights = weights\n",
        "\n",
        "    def forward(self, inputs):  # pylint: disable=arguments-differ\n",
        "        \"\"\"Evaluates a forward pass through the QNode based upon input data and the initialized\n",
        "        weights.\n",
        "\n",
        "        Args:\n",
        "            inputs (tensor): data to be processed\n",
        "\n",
        "        Returns:\n",
        "            tensor: output data\n",
        "        \"\"\"\n",
        "\n",
        "        if len(inputs.shape) > 1:\n",
        "            # If the input size is not 1-dimensional, unstack the input along its first dimension,\n",
        "            # recursively call the forward pass on each of the yielded tensors, and then stack the\n",
        "            # outputs back into the correct shape\n",
        "            reconstructor = [self.forward(x) for x in torch.unbind(inputs)]\n",
        "            return torch.stack(reconstructor)\n",
        "\n",
        "        # If the input is 1-dimensional, calculate the forward pass as usual\n",
        "        return self._evaluate_qnode(inputs)\n",
        "\n",
        "\n",
        "    def _evaluate_qnode(self, x):\n",
        "        \"\"\"Evaluates the QNode for a single input datapoint.\n",
        "\n",
        "        Args:\n",
        "            x (tensor): the datapoint\n",
        "\n",
        "        Returns:\n",
        "            tensor: output datapoint\n",
        "        \"\"\"\n",
        "        kwargs = {\n",
        "            **{self.input_arg: x},\n",
        "            **{arg: weight.to(x) for arg, weight in self.qnode_weights.items()},\n",
        "        }\n",
        "        res = self.qnode(**kwargs)\n",
        "\n",
        "        if isinstance(res, torch.Tensor):\n",
        "            return res.type(x.dtype)\n",
        "\n",
        "        return torch.hstack(res).type(x.dtype)\n",
        "\n",
        "    def __str__(self):\n",
        "        detail = \"<Quantum Torch Layer: func={}>\"\n",
        "        return detail.format(self.qnode.func.__name__)\n",
        "\n",
        "    __repr__ = __str__\n",
        "    _input_arg = \"inputs\"\n",
        "\n",
        "    @property\n",
        "    def input_arg(self):\n",
        "        \"\"\"Name of the argument to be used as the input to the Torch layer. Set to ``\"inputs\"``.\"\"\"\n",
        "        return self._input_arg"
      ],
      "metadata": {
        "id": "n2FNBYH1YJwU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "698TlmaywBez"
      },
      "outputs": [],
      "source": [
        "class QSAL_pennylane(torch.nn.Module):\n",
        "    def __init__(self,S,n,Denc,D):\n",
        "        super().__init__()\n",
        "        self.seq_num=S\n",
        "        self.init_params_Q=torch.nn.Parameter(torch.stack([(np.pi/4) * (2 * torch.randn(n*(D+2)) - 1) for _ in range(self.seq_num)]))\n",
        "        self.init_params_K=torch.nn.Parameter(torch.stack([(np.pi/4) * (2 * torch.randn(n*(D+2)) - 1) for _ in range(self.seq_num)]))\n",
        "        self.init_params_V=torch.nn.Parameter(torch.stack([(np.pi/4) * (2 * torch.randn(n*(D+2)) - 1) for _ in range(self.seq_num)]))\n",
        "        self.num_q=n\n",
        "        self.Denc=Denc\n",
        "        self.D=D\n",
        "        self.d=n*(Denc+2)\n",
        "        self.dev = qml.device(\"default.qubit\", wires=self.num_q)\n",
        "        \n",
        "        self.vqnod=qml.QNode(self.circuit_v, self.dev, interface=\"torch\")\n",
        "        self.qnod=qml.QNode(self.circuit_qk, self.dev, interface=\"torch\")\n",
        "        self.weight_v = [{\"weights\": self.init_params_V[i]} for i in range(self.seq_num)]\n",
        "        self.weight_q = [{\"weights\": self.init_params_Q[i]} for i in range(self.seq_num)]\n",
        "        self.weight_k = [{\"weights\": self.init_params_K[i]} for i in range(self.seq_num)]\n",
        "        #self.v_linear ={} #[qml.qnn.TorchLayer(self.vqnod[i], self.weight_shapes) for i in range(self.seq_num)]\n",
        "        #for i in range(self.seq_num):\n",
        "        self.v_linear = [TorchLayer(self.vqnod, self.weight_v[i]) for i in range(self.seq_num)]\n",
        "        self.q_linear = [TorchLayer(self.qnod, self.weight_q[i]) for i in range(self.seq_num)]\n",
        "        self.k_linear = [TorchLayer(self.qnod, self.weight_k[i]) for i in range(self.seq_num)]\n",
        "        #self.qqnod=[qml.QNode(self.circuit_qk, self.dev, interface=\"torch\") for i in range(self.seq_num)]\n",
        "\n",
        "    def random_op(self):\n",
        "        a=random.randint(0, 4)\n",
        "        if a==0:\n",
        "            op=qml.Identity(0)\n",
        "        elif a==1:\n",
        "            op=qml.PauliX(0)\n",
        "        elif a==2:\n",
        "            op=qml.PauliY(0)\n",
        "        else:\n",
        "            op=qml.PauliZ(0)\n",
        "\n",
        "        op_elimated=qml.Identity(0)\n",
        "        for i in range(1,self.num_q):\n",
        "            op_elimated=op_elimated@qml.Identity(i)\n",
        "        Select_wrong=True\n",
        "        while Select_wrong:\n",
        "            for i in range(1,self.num_q):\n",
        "                a=random.randint(0, 4)\n",
        "                if a==0:\n",
        "                    op=op@qml.Identity(i)\n",
        "                elif a==1:\n",
        "                    op=op@qml.PauliX(i)\n",
        "                elif a==2:\n",
        "                    op=op@qml.PauliY(i)\n",
        "                else:\n",
        "                    op=op@qml.PauliZ(i)\n",
        "            if op!=op_elimated:\n",
        "                Select_wrong=False\n",
        "        return op\n",
        "\n",
        "    def circuit_v(self,inputs,weights):\n",
        "            op=self.random_op()\n",
        "            # feature_map\n",
        "            indx=0\n",
        "            for j in range(self.num_q):\n",
        "                qml.RX(inputs[indx],j)\n",
        "                qml.RY(inputs[indx+1],j)\n",
        "                indx+=2\n",
        "            for i in range(self.Denc):\n",
        "                for j in range(self.num_q):\n",
        "                    qml.CNOT(wires=(j,(j+1)%self.num_q))\n",
        "\n",
        "                for j in range(self.num_q):\n",
        "                    qml.RY(inputs[indx],j)\n",
        "                    indx+=1\n",
        "            # Ansatz\n",
        "            indx=0\n",
        "            for j in range(self.num_q):\n",
        "                qml.RX(weights[indx],j)\n",
        "                qml.RY(weights[indx+1],j)\n",
        "                indx+=2\n",
        "            for i in range(self.D):\n",
        "                for j in range(self.num_q):\n",
        "                    qml.CNOT(wires=(j,(j+1)%self.num_q))\n",
        "                    \n",
        "                for j in range(self.num_q):\n",
        "                    #qc.rx(params[indx],j)\n",
        "                    qml.RY(weights[indx],j)\n",
        "                    indx+=1\n",
        "            return [qml.expval(op) for i in range(self.d)] \n",
        "\n",
        "    def circuit_qk(self,inputs,weights):\n",
        "        op=self.random_op()\n",
        "        # feature_map\n",
        "        indx=0\n",
        "        for j in range(self.num_q):\n",
        "            qml.RX(inputs[indx],j)\n",
        "            qml.RY(inputs[indx+1],j)\n",
        "            indx+=2\n",
        "        for i in range(self.Denc):\n",
        "            for j in range(self.num_q):\n",
        "                qml.CNOT(wires=(j,(j+1)%self.num_q))\n",
        "\n",
        "            for j in range(self.num_q):\n",
        "                qml.RY(inputs[indx],j)\n",
        "                indx+=1\n",
        "        # Ansatz\n",
        "        indx=0\n",
        "        for j in range(self.num_q):\n",
        "            qml.RX(weights[indx],j)\n",
        "            qml.RY(weights[indx+1],j)\n",
        "            indx+=2\n",
        "        for i in range(self.D):\n",
        "            for j in range(self.num_q):\n",
        "                qml.CNOT(wires=(j,(j+1)%self.num_q))\n",
        "                \n",
        "            for j in range(self.num_q):\n",
        "                #qc.rx(params[indx],j)\n",
        "                qml.RY(weights[indx],j)\n",
        "                indx+=1\n",
        "        return [qml.expval(qml.PauliZ(0))]\n",
        "\n",
        "    def forward(self,input):\n",
        "\n",
        "        Q_output=torch.stack([self.q_linear[i](input[:,i]) for i in range(self.seq_num)])\n",
        "        K_output=torch.stack([self.k_linear[i](input[:,i]) for i in range(self.seq_num)])\n",
        "        V_output=torch.stack([self.v_linear[i](input[:,i]) for i in range(self.seq_num)])\n",
        "        \n",
        "        batch_size=len(input)\n",
        "        Q_output=Q_output.transpose(0,2).repeat((self.seq_num,1,1))\n",
        "        K_output=K_output.transpose(0,2).repeat((self.seq_num,1,1)).transpose(0,2)\n",
        "        #print(V_output.size())\n",
        "        #Q_grid, K_grid=torch.meshgrid(Q_output, K_output, indexing='ij')\n",
        "        alpha=torch.exp(-(Q_output-K_output)**2)\n",
        "        alpha=alpha.transpose(0,1)\n",
        "        V_output=V_output.transpose(0,1)\n",
        "        output=[]\n",
        "\n",
        "        for i in range(self.seq_num):\n",
        "            \n",
        "            Sum_a=torch.sum(alpha[:,i,:],-1)\n",
        "            div_sum_a=(1/Sum_a).repeat(self.d,self.seq_num,1).transpose(0,2)\n",
        "            \n",
        "            Sum_w=torch.sum(alpha[:,:,i].repeat((self.d,1,1)).transpose(0,2).transpose(0,1)*V_output*div_sum_a,1)\n",
        "            output.append(Sum_w)\n",
        "        return input+torch.stack(output).transpose(0,1)\n",
        "\n",
        "class QSANN_pennylane(torch.nn.Module):\n",
        "    def __init__(self,S,n,Denc,D,num_layers):\n",
        "        \"\"\"\n",
        "        # input: input data\n",
        "        # weight: trainable parameter\n",
        "        # n: # of of qubits\n",
        "        # d: embedding dimension which is equal to n(Denc+2)\n",
        "        # Denc: the # number of layers for encoding \n",
        "        # D: the # of layers of variational layers\n",
        "        # type \"K\": key, \"Q\": Query, \"V\": value\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.qsal_lst=[QSAL_pennylane(S,n,Denc,D) for _ in range(num_layers)]\n",
        "        self.qnn=nn.Sequential(*self.qsal_lst)\n",
        "\n",
        "    def forward(self,input):\n",
        "\n",
        "        return self.qnn(input)\n",
        "\n",
        "class QSANN_text_classifier(torch.nn.Module):\n",
        "    def __init__(self,S,n,Denc,D,num_layers):\n",
        "        \"\"\"\n",
        "        # input: input data\n",
        "        # weight: trainable parameter\n",
        "        # n: # of of qubits\n",
        "        # d: embedding dimension which is equal to n(Denc+2)\n",
        "        # Denc: the # number of layers for encoding \n",
        "        # D: the # of layers of variational layers\n",
        "        # type \"K\": key, \"Q\": Query, \"V\": value\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.Qnn=QSANN_pennylane(S,n,Denc,D,num_layers)\n",
        "        self.final_layer=nn.Linear(n*(Denc+2)*S, 1)\n",
        "        self.final_layer=self.final_layer.float()\n",
        "\n",
        "    def forward(self,input):\n",
        "\n",
        "        x=self.Qnn(input)\n",
        "        x=torch.flatten(x,start_dim=1)\n",
        "        \n",
        "        return torch.sigmoid(self.final_layer(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Toy data"
      ],
      "metadata": {
        "id": "Az3vdS66nLI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=[[np.array([random.random() for _ in range(6)]) for _ in range(5)] for _ in range(32)]\n",
        "Y=[random.randint(0,1) for _ in range(32)]"
      ],
      "metadata": {
        "id": "JpoTaixqJWFt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=QSANN_text_classifier(5,2,1,1,2)"
      ],
      "metadata": {
        "id": "cotznOSukK07"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(lr=0.03, params=model.parameters())"
      ],
      "metadata": {
        "id": "PaGx4pR4kGnn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aedvM_69kJfy",
        "outputId": "f2de57e4-2ca1-4eaa-acc5-7fa2d95f16a1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ctPaQxVylYqT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = (torch.round(torch.sign(preds-0.5))+1)//2\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "XxZVEHIklUCv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iepoch in tqdm(range(10)):\n",
        "    optimizer.zero_grad()\n",
        "    X_tensor=torch.tensor(X)\n",
        "    predictions=model(X_tensor.float()).squeeze(1)\n",
        "    #predictions=torch.sign(predictions)\n",
        "    label=torch.tensor(Y)\n",
        "    loss = criterion(predictions, label.float())\n",
        "    acc = binary_accuracy(predictions, label)\n",
        "    print('')\n",
        "    print('Accuracy:',acc)\n",
        "    print('')\n",
        "    print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3MCMNqvkj0U",
        "outputId": "106dfa58-7ad6-4cf7-e1ad-1405334c7c90"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5312)\n",
            "\n",
            "tensor(51.8366, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:21<03:11, 21.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5625)\n",
            "\n",
            "tensor(51.4881, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:43<02:54, 21.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5312)\n",
            "\n",
            "tensor(52.0734, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [01:05<02:32, 21.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5312)\n",
            "\n",
            "tensor(51.6744, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:26<02:09, 21.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5938)\n",
            "\n",
            "tensor(51.3703, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:49<01:50, 22.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5000)\n",
            "\n",
            "tensor(51.7356, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [02:14<01:32, 23.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5000)\n",
            "\n",
            "tensor(51.8536, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [02:36<01:07, 22.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8125)\n",
            "\n",
            "tensor(50.8496, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [02:58<00:45, 22.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7188)\n",
            "\n",
            "tensor(50.7651, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [03:21<00:22, 22.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6250)\n",
            "\n",
            "tensor(51.0952, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [03:44<00:00, 22.45s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real Data"
      ],
      "metadata": {
        "id": "B-ZGZr2hpBpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = (torch.round(torch.sign(preds-0.5))+1)//2\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "KZeKclafmfpy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = QSANN_text_classifier(10,2,8,1,1)"
      ],
      "metadata": {
        "id": "nCcmO9ASpUCG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(lr=0.005, params=model.parameters())\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "8EcbuxaKpV0o"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nM5uFRepYO0",
        "outputId": "9471e2e0-23d8-4912-97f2-7339326d30c2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for iepoch in tqdm(range(40)):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    idx = torch.randperm(128)[:32]\n",
        "    X_batch = new_X_train[idx]\n",
        "    predictions=model(X_batch.float()).squeeze(1)\n",
        "\n",
        "    label_batch=label[idx]\n",
        "    loss = criterion(predictions, label_batch.float())\n",
        "    acc = binary_accuracy(predictions,label_batch)\n",
        "    print('')\n",
        "    print('Accuracy:',acc)\n",
        "    print('')\n",
        "    print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dcpQI9xpaDs",
        "outputId": "c763e9bd-fbcd-4f5a-d203-d6b448b59439"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/40 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5000)\n",
            "\n",
            "tensor(59.0043, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▎         | 1/40 [00:48<31:23, 48.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5312)\n",
            "\n",
            "tensor(58.5009, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 2/40 [01:29<28:07, 44.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.4688)\n",
            "\n",
            "tensor(51.9091, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 3/40 [02:12<26:48, 43.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5625)\n",
            "\n",
            "tensor(62.3832, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 4/40 [02:55<26:00, 43.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5312)\n",
            "\n",
            "tensor(58.7561, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 5/40 [03:38<25:08, 43.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5625)\n",
            "\n",
            "tensor(61.9742, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 6/40 [04:19<24:00, 42.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5625)\n",
            "\n",
            "tensor(62.2131, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 7/40 [05:01<23:15, 42.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.4062)\n",
            "\n",
            "tensor(44.9191, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 8/40 [05:43<22:37, 42.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.4375)\n",
            "\n",
            "tensor(37.6110, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▎       | 9/40 [06:27<22:03, 42.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5312)\n",
            "\n",
            "tensor(47.9658, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 10/40 [07:09<21:16, 42.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7188)\n",
            "\n",
            "tensor(54.5259, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 11/40 [07:51<20:32, 42.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5625)\n",
            "\n",
            "tensor(62.0551, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 12/40 [08:33<19:41, 42.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5938)\n",
            "\n",
            "tensor(58.3563, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▎      | 13/40 [09:15<19:01, 42.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5938)\n",
            "\n",
            "tensor(58.1885, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 14/40 [09:57<18:12, 42.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6250)\n",
            "\n",
            "tensor(61.7527, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 15/40 [10:38<17:20, 41.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8438)\n",
            "\n",
            "tensor(43.9029, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 16/40 [11:20<16:42, 41.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7500)\n",
            "\n",
            "tensor(54.5725, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▎     | 17/40 [12:03<16:13, 42.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7812)\n",
            "\n",
            "tensor(57.5301, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 18/40 [12:46<15:31, 42.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5312)\n",
            "\n",
            "tensor(47.6903, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 19/40 [13:27<14:45, 42.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7188)\n",
            "\n",
            "tensor(61.0643, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 20/40 [14:10<14:06, 42.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6562)\n",
            "\n",
            "tensor(64.9691, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▎    | 21/40 [14:54<13:33, 42.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5938)\n",
            "\n",
            "tensor(51.1004, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 22/40 [15:38<12:54, 43.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7812)\n",
            "\n",
            "tensor(61.4108, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▊    | 23/40 [16:22<12:18, 43.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8125)\n",
            "\n",
            "tensor(54.0725, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 24/40 [17:03<11:23, 42.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7500)\n",
            "\n",
            "tensor(75.3535, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 25/40 [17:46<10:41, 42.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6562)\n",
            "\n",
            "tensor(47.6357, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 26/40 [18:27<09:52, 42.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7500)\n",
            "\n",
            "tensor(57.3674, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 27/40 [19:11<09:16, 42.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8125)\n",
            "\n",
            "tensor(57.4531, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 28/40 [19:54<08:32, 42.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8125)\n",
            "\n",
            "tensor(54.0554, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▎  | 29/40 [20:35<07:43, 42.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6562)\n",
            "\n",
            "tensor(43.7544, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 30/40 [21:18<07:06, 42.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7500)\n",
            "\n",
            "tensor(57.3511, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 31/40 [22:02<06:26, 42.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6562)\n",
            "\n",
            "tensor(50.4602, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 32/40 [22:45<05:43, 42.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7812)\n",
            "\n",
            "tensor(61.2342, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▎ | 33/40 [23:28<05:00, 42.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8125)\n",
            "\n",
            "tensor(46.7355, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 34/40 [24:12<04:19, 43.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7188)\n",
            "\n",
            "tensor(68.2509, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 35/40 [24:54<03:35, 43.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8438)\n",
            "\n",
            "tensor(60.7025, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 36/40 [25:37<02:51, 42.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7812)\n",
            "\n",
            "tensor(57.4961, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▎| 37/40 [26:20<02:08, 42.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7188)\n",
            "\n",
            "tensor(53.8565, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 38/40 [27:03<01:25, 42.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7812)\n",
            "\n",
            "tensor(53.6991, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 39/40 [27:45<00:42, 42.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.9062)\n",
            "\n",
            "tensor(46.1245, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [28:27<00:00, 42.69s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_batch = new_X_train\n",
        "predictions=model(X_batch.float()).squeeze(1)\n",
        "\n",
        "loss = criterion(predictions, label.float())\n",
        "acc = binary_accuracy(predictions,label)\n",
        "print('')\n",
        "print('Accuracy:',acc)\n",
        "print('')\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwBHQ2cDpeCi",
        "outputId": "622bc757-2134-4acd-8518-97992268ad39"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8438)\n",
            "\n",
            "tensor(302.8917, grad_fn=<DivBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_test=torch.stack(new_y_test)"
      ],
      "metadata": {
        "id": "MsKWTIMZphYS"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_batch = torch.stack(new_X_test)\n",
        "predictions=model(X_batch.float()).squeeze(1)\n",
        "\n",
        "loss = criterion(predictions, label_test.float())\n",
        "acc = binary_accuracy(predictions,label_test)\n",
        "print('')\n",
        "print('Accuracy:',acc)\n",
        "print('')\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enYd1lb8pi4J",
        "outputId": "c6fb418a-dd23-4f6d-ab1e-e895c68d7544"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.4062)\n",
            "\n",
            "tensor(312.7864, grad_fn=<DivBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name=path+'QSANN_pennylane_model'\n",
        "torch.save(model.state_dict(),file_name)"
      ],
      "metadata": {
        "id": "nDW4hjkqplJI"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ngphQzbyxVSV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
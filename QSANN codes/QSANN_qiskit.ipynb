{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR7DHQg4yCjB",
        "outputId": "3ae30c15-cdee-4096-ea4e-6bab43d3cba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting qiskit\n",
            "  Downloading qiskit-0.43.0.tar.gz (10.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting qiskit-terra==0.24.0 (from qiskit)\n",
            "  Downloading qiskit_terra-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qiskit-aer==0.12.0 (from qiskit)\n",
            "  Downloading qiskit_aer-0.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qiskit-ibmq-provider==0.20.2 (from qiskit)\n",
            "  Downloading qiskit_ibmq_provider-0.20.2-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.5/241.5 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer==0.12.0->qiskit) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer==0.12.0->qiskit) (1.10.1)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibmq-provider==0.20.2->qiskit) (2.27.1)\n",
            "Collecting requests-ntlm<=1.1.0 (from qiskit-ibmq-provider==0.20.2->qiskit)\n",
            "  Downloading requests_ntlm-1.1.0-py2.py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibmq-provider==0.20.2->qiskit) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibmq-provider==0.20.2->qiskit) (2.8.2)\n",
            "Requirement already satisfied: websocket-client>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibmq-provider==0.20.2->qiskit) (1.5.1)\n",
            "Collecting websockets>=10.0 (from qiskit-ibmq-provider==0.20.2->qiskit)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rustworkx>=0.12.0 (from qiskit-terra==0.24.0->qiskit)\n",
            "  Downloading rustworkx-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ply>=3.10 (from qiskit-terra==0.24.0->qiskit)\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra==0.24.0->qiskit) (5.9.5)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra==0.24.0->qiskit) (1.11.1)\n",
            "Collecting dill>=0.3 (from qiskit-terra==0.24.0->qiskit)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stevedore>=3.0.0 (from qiskit-terra==0.24.0->qiskit)\n",
            "  Downloading stevedore-5.1.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting symengine<0.10,>=0.9 (from qiskit-terra==0.24.0->qiskit)\n",
            "  Downloading symengine-0.9.2-cp310-cp310-manylinux2010_x86_64.whl (37.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.5/37.5 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider==0.20.2->qiskit) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.20.2->qiskit) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.20.2->qiskit) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.20.2->qiskit) (3.4)\n",
            "Collecting ntlm-auth>=1.0.2 (from requests-ntlm<=1.1.0->qiskit-ibmq-provider==0.20.2->qiskit)\n",
            "  Downloading ntlm_auth-1.5.0-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.10/dist-packages (from requests-ntlm<=1.1.0->qiskit-ibmq-provider==0.20.2->qiskit) (40.0.2)\n",
            "Collecting pbr!=2.1.0,>=2.0.0 (from stevedore>=3.0.0->qiskit-terra==0.24.0->qiskit)\n",
            "  Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.7/112.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit-terra==0.24.0->qiskit) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=1.3->requests-ntlm<=1.1.0->qiskit-ibmq-provider==0.20.2->qiskit) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm<=1.1.0->qiskit-ibmq-provider==0.20.2->qiskit) (2.21)\n",
            "Building wheels for collected packages: qiskit\n",
            "  Building wheel for qiskit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qiskit: filename=qiskit-0.43.0-py3-none-any.whl size=7996 sha256=22635c36c3ddc34602055235d7c39ae1c23bb61268b55eae2dc54356801ffb28\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/fe/bc/59531707126e693bad48c61c0b86f3870b49f8f7ad49c18209\n",
            "Successfully built qiskit\n",
            "Installing collected packages: ply, websockets, symengine, rustworkx, pbr, ntlm-auth, dill, stevedore, requests-ntlm, qiskit-terra, qiskit-ibmq-provider, qiskit-aer, qiskit\n",
            "Successfully installed dill-0.3.6 ntlm-auth-1.5.0 pbr-5.11.1 ply-3.11 qiskit-0.43.0 qiskit-aer-0.12.0 qiskit-ibmq-provider-0.20.2 qiskit-terra-0.24.0 requests-ntlm-1.1.0 rustworkx-0.12.1 stevedore-5.1.0 symengine-0.9.2 websockets-11.0.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pylatexenc\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136820 sha256=85c2c3cd91323a212b61ae7a7b35bf7f0616cf85f8de87a32ea9d2589b49f70e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/31/8b/e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: pylatexenc\n",
            "Successfully installed pylatexenc-2.10\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting qiskit.ignis\n",
            "  Downloading qiskit_ignis-0.7.1-py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.7/198.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from qiskit.ignis) (1.22.4)\n",
            "Requirement already satisfied: qiskit-terra>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from qiskit.ignis) (0.24.0)\n",
            "Collecting retworkx>=0.8.0 (from qiskit.ignis)\n",
            "  Downloading retworkx-0.12.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: scipy!=0.19.1,>=0.19 in /usr/local/lib/python3.10/dist-packages (from qiskit.ignis) (1.10.1)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit.ignis) (67.7.2)\n",
            "Requirement already satisfied: rustworkx>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.15.1->qiskit.ignis) (0.12.1)\n",
            "Requirement already satisfied: ply>=3.10 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.15.1->qiskit.ignis) (3.11)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.15.1->qiskit.ignis) (5.9.5)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.15.1->qiskit.ignis) (1.11.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.15.1->qiskit.ignis) (0.3.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.15.1->qiskit.ignis) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.15.1->qiskit.ignis) (5.1.0)\n",
            "Requirement already satisfied: symengine<0.10,>=0.9 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.15.1->qiskit.ignis) (0.9.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit-terra>=0.15.1->qiskit.ignis) (1.16.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit-terra>=0.15.1->qiskit.ignis) (5.11.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit-terra>=0.15.1->qiskit.ignis) (1.3.0)\n",
            "Installing collected packages: retworkx, qiskit.ignis\n",
            "Successfully installed qiskit.ignis-0.7.1 retworkx-0.12.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting qiskit_machine_learning\n",
            "  Downloading qiskit_machine_learning-0.6.1-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.7/148.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: qiskit-terra>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (0.24.0)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.22.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.2.2)\n",
            "Collecting fastdtw (from qiskit_machine_learning)\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (67.7.2)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (0.3.6)\n",
            "Requirement already satisfied: rustworkx>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.22.2->qiskit_machine_learning) (0.12.1)\n",
            "Requirement already satisfied: ply>=3.10 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.22.2->qiskit_machine_learning) (3.11)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.22.2->qiskit_machine_learning) (1.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.22.2->qiskit_machine_learning) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.22.2->qiskit_machine_learning) (5.1.0)\n",
            "Requirement already satisfied: symengine<0.10,>=0.9 in /usr/local/lib/python3.10/dist-packages (from qiskit-terra>=0.22.2->qiskit_machine_learning) (0.9.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->qiskit_machine_learning) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->qiskit_machine_learning) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit-terra>=0.22.2->qiskit_machine_learning) (1.16.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit-terra>=0.22.2->qiskit_machine_learning) (5.11.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit-terra>=0.22.2->qiskit_machine_learning) (1.3.0)\n",
            "Building wheels for collected packages: fastdtw\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp310-cp310-linux_x86_64.whl size=517895 sha256=3024885639863358e4ab99239488b44df61f2a6942442e710501f529ca8c253e\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/c8/f7/c25448dab74c3acf4848bc25d513c736bb93910277e1528ef4\n",
            "Successfully built fastdtw\n",
            "Installing collected packages: fastdtw, qiskit_machine_learning\n",
            "Successfully installed fastdtw-0.3.4 qiskit_machine_learning-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit\n",
        "!pip install pylatexenc\n",
        "!pip install qiskit.ignis\n",
        "!pip install qiskit_machine_learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVOr3qrBxLf_"
      },
      "outputs": [],
      "source": [
        "from qiskit import *\n",
        "# Qiskit module\n",
        "from qiskit import QuantumCircuit\n",
        "import qiskit.circuit.library as circuit_library\n",
        "import qiskit.quantum_info as qi\n",
        "#from qiskit import execute\n",
        "from qiskit.utils import algorithm_globals\n",
        "from qiskit.circuit.library import EfficientSU2\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "import torch\n",
        "from qiskit.circuit import ParameterVector\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U3YhfSqLvq6",
        "outputId": "99762eee-d672-4df2-e7ce-688a61606814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/gdrive/MyDrive/New_test/'"
      ],
      "metadata": {
        "id": "LP5quaQ0Lp_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "E8bOsYJqLLZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXrMD39H6pFL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c16c21d-4e5e-47c7-c43f-85a1ba565fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "vocab_size = 1000\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "class_names = [\"Negative\", \"Positive\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select dataset evenly \n",
        "selected_num=128\n",
        "\n",
        "new_x_train=[]\n",
        "new_y_train=[]\n",
        "indx=0\n",
        "while len(new_x_train) < selected_num:\n",
        "    if len(x_train[indx]) <= 200:\n",
        "        sum_y=np.sum(new_y_train)\n",
        "        len_y=len(new_y_train)\n",
        "        if sum_y >= selected_num//2:\n",
        "            if y_train[indx]==0:\n",
        "                new_x_train.append(x_train[indx])\n",
        "                new_y_train.append(y_train[indx])\n",
        "                indx+=1\n",
        "            else:\n",
        "                indx+=1\n",
        "                continue\n",
        "        elif ((len_y-sum_y) >= selected_num//2):\n",
        "            if y_train[indx]==1:\n",
        "                new_x_train.append(x_train[indx])\n",
        "                new_y_train.append(y_train[indx])\n",
        "                indx+=1\n",
        "            else:\n",
        "                indx+=1\n",
        "                continue\n",
        "        else:\n",
        "            new_x_train.append(x_train[indx])\n",
        "            new_y_train.append(y_train[indx])\n",
        "            indx+=1\n",
        "    else:\n",
        "        indx+=1\n",
        "\n",
        "selected_num=128\n",
        "\n",
        "new_x_test=[]\n",
        "new_y_test=[]\n",
        "indx=0\n",
        "while len(new_x_test) < selected_num:\n",
        "    if len(x_test[indx]) <= 200:\n",
        "        sum_y=np.sum(new_y_test)\n",
        "        len_y=len(new_y_test)\n",
        "        if sum_y >= selected_num//2:\n",
        "            if y_test[indx]==0:\n",
        "                new_x_test.append(x_test[indx])\n",
        "                new_y_test.append(y_test[indx])\n",
        "                indx+=1\n",
        "            else:\n",
        "                indx+=1\n",
        "                continue\n",
        "        elif ((len_y-sum_y) >= selected_num//2):\n",
        "            if y_test[indx]==1:\n",
        "                new_x_test.append(x_test[indx])\n",
        "                new_y_test.append(y_test[indx])\n",
        "                indx+=1\n",
        "            else:\n",
        "                indx+=1\n",
        "                continue\n",
        "        else:\n",
        "            new_x_test.append(x_test[indx])\n",
        "            new_y_test.append(y_test[indx])\n",
        "            indx+=1\n",
        "    else:\n",
        "        indx+=1"
      ],
      "metadata": {
        "id": "uhemkUEeb2X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fepcT7Ulajfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3447c72e-58cb-4a79-9372-2cde3ecfc5ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b98d59874a29>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_train=np.array(new_x_train)#[:128]\n",
            "<ipython-input-7-b98d59874a29>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  x_test=np.array(new_x_test)#[:128]\n"
          ]
        }
      ],
      "source": [
        "x_train=np.array(new_x_train)#[:128]\n",
        "y_train=np.array(new_y_train)#[:128]\n",
        "\n",
        "x_test=np.array(new_x_test)#[:128]\n",
        "y_test=np.array(new_y_test)#[:128]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81Me9ys1A1m-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ae4baa-7822-4e08-dd6d-c317f847ceef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Get the word index from the dataset\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "\n",
        "# Ensure that \"special\" words are mapped into human readable terms \n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNKNOWN>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "# Perform reverse word lookup and make it callable\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdIvSMKKEpJy",
        "outputId": "2bfe8ef1-bc99-4253-922b-7cae7acf33fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum review length: 200\n",
            "Minimum review length: 19\n",
            "Mean review length: 132.546875\n",
            "\n",
            "Machine readable Review\n",
            "  Review Text: [1, 13, 244, 6, 666, 337, 7, 2, 2, 5, 28, 296, 958, 7, 27, 102, 366, 150, 5, 600, 7, 98, 28, 2, 8, 97, 72, 462, 2, 122, 89, 8, 2, 369, 5, 2, 84, 10, 10, 14, 20, 9, 2, 44, 6, 132, 52, 17, 2, 84, 125, 190, 29, 47, 35, 2, 270, 7, 2, 15, 2, 90, 39, 399, 183, 15, 238, 43, 97, 90, 804, 21, 11, 4, 130, 29, 630, 56, 399, 98, 4, 2, 7, 113, 10, 10, 4, 20, 9, 73, 2, 19, 486, 883, 52, 116, 5, 82, 6, 227, 7, 6, 2, 837, 94, 31, 7, 148, 102, 121, 25, 100, 43, 30, 654, 54, 12, 630]\n",
            "  Review Sentiment: 1\n",
            "\n",
            "Human Readable Review\n",
            "  Review Text: <START> big <UNKNOWN> big <UNKNOWN> bad music and a <UNKNOWN> <UNKNOWN> <UNKNOWN> these are the words to best <UNKNOWN> this terrible movie i love cheesy horror movies and i've seen <UNKNOWN> but this had got to be on of the worst ever made the plot is <UNKNOWN> <UNKNOWN> and ridiculous the acting is an <UNKNOWN> the script is completely <UNKNOWN> the best is the end <UNKNOWN> with the <UNKNOWN> and how he worked out who the killer is it's just so <UNKNOWN> <UNKNOWN> written the <UNKNOWN> are <UNKNOWN> and funny in <UNKNOWN> <UNKNOWN> the <UNKNOWN> is big lots of <UNKNOWN> <UNKNOWN> men <UNKNOWN> those cut <UNKNOWN> <UNKNOWN> that show off their <UNKNOWN> <UNKNOWN> that men actually <UNKNOWN> them and the music is just <UNKNOWN> <UNKNOWN> that plays over and over again in almost every scene there is <UNKNOWN> music <UNKNOWN> and <UNKNOWN> taking away <UNKNOWN> and the <UNKNOWN> still doesn't close for <UNKNOWN> all <UNKNOWN> <UNKNOWN> this is a truly bad film whose only <UNKNOWN> is to look back on the <UNKNOWN> that was the <UNKNOWN> and have a good old laugh at how bad everything was back then\n",
            "  Review Sentiment: Negative\n"
          ]
        }
      ],
      "source": [
        "# Concatonate test and training datasets\n",
        "allreviews = np.concatenate((x_train, x_test), axis=0)\n",
        "\n",
        "# Review lengths across test and training whole datasets\n",
        "print(\"Maximum review length: {}\".format(len(max((allreviews), key=len))))\n",
        "print(\"Minimum review length: {}\".format(len(min((allreviews), key=len))))\n",
        "result = [len(x) for x in allreviews]\n",
        "print(\"Mean review length: {}\".format(np.mean(result)))\n",
        "\n",
        "# Print a review and it's class as stored in the dataset. Replace the number\n",
        "# to select a different review.\n",
        "print(\"\")\n",
        "print(\"Machine readable Review\")\n",
        "print(\"  Review Text: \" + str(x_train[60]))\n",
        "print(\"  Review Sentiment: \" + str(y_train[60]))\n",
        "\n",
        "# Print a review and it's class in human readable format. Replace the number\n",
        "# to select a different review.\n",
        "print(\"\")\n",
        "print(\"Human Readable Review\")\n",
        "print(\"  Review Text: \" + decode_review(x_train[0]))\n",
        "print(\"  Review Sentiment: \" + class_names[y_train[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHp7KqozRWG0",
        "outputId": "d73c5edb-801b-4fff-d177-1cf290484b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape Training Review Data: (128, 200)\n",
            "Shape Training Class Data: (128,)\n",
            "Shape Test Review Data: (128, 200)\n",
            "Shape Test Class Data: (128,)\n",
            "\n",
            "Human Readable Review Text (post padding): <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> big <UNKNOWN> big <UNKNOWN> bad music and a <UNKNOWN> <UNKNOWN> <UNKNOWN> these are the words to best <UNKNOWN> this terrible movie i love cheesy horror movies and i've seen <UNKNOWN> but this had got to be on of the worst ever made the plot is <UNKNOWN> <UNKNOWN> and ridiculous the acting is an <UNKNOWN> the script is completely <UNKNOWN> the best is the end <UNKNOWN> with the <UNKNOWN> and how he worked out who the killer is it's just so <UNKNOWN> <UNKNOWN> written the <UNKNOWN> are <UNKNOWN> and funny in <UNKNOWN> <UNKNOWN> the <UNKNOWN> is big lots of <UNKNOWN> <UNKNOWN> men <UNKNOWN> those cut <UNKNOWN> <UNKNOWN> that show off their <UNKNOWN> <UNKNOWN> that men actually <UNKNOWN> them and the music is just <UNKNOWN> <UNKNOWN> that plays over and over again in almost every scene there is <UNKNOWN> music <UNKNOWN> and <UNKNOWN> taking away <UNKNOWN> and the <UNKNOWN> still doesn't close for <UNKNOWN> all <UNKNOWN> <UNKNOWN> this is a truly bad film whose only <UNKNOWN> is to look back on the <UNKNOWN> that was the <UNKNOWN> and have a good old laugh at how bad everything was back then\n"
          ]
        }
      ],
      "source": [
        "# The length of reviews\n",
        "review_length = 200\n",
        "\n",
        "# Padding / truncated our reviews\n",
        "x_train = sequence.pad_sequences(x_train, maxlen = review_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen = review_length)\n",
        "\n",
        "# Check the size of our datasets. Review data for both test and training should \n",
        "# contain 25000 reviews of 500 integers. Class data should contain 25000 values, \n",
        "# one for each review. Class values are 0 or 1, indicating a negative \n",
        "# or positive review.\n",
        "print(\"Shape Training Review Data: \" + str(x_train.shape))\n",
        "print(\"Shape Training Class Data: \" + str(np.shape(y_train)))\n",
        "print(\"Shape Test Review Data: \" + str(x_test.shape))\n",
        "print(\"Shape Test Class Data: \" + str(y_test.shape))\n",
        "\n",
        "# Note padding is added to start of review, not the end\n",
        "print(\"\")\n",
        "print(\"Human Readable Review Text (post padding): \" + decode_review(x_train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpePyC_tcLni"
      },
      "outputs": [],
      "source": [
        "new_X_train=[]\n",
        "for seq in x_train:\n",
        "    a=torch.tensor(np.pi*(seq/1000-0.5))\n",
        "    new_X_train.append(torch.reshape(a, (10, 20)))\n",
        "\n",
        "new_y_train=[]\n",
        "for seq in y_train:\n",
        "    new_y_train.append(torch.tensor(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q31IP-3DgVQj"
      },
      "outputs": [],
      "source": [
        "new_X_train=torch.stack(new_X_train)\n",
        "\n",
        "label=torch.stack(new_y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_X_test=[]\n",
        "for seq in x_test:\n",
        "    a=torch.tensor(np.pi*(seq/1000-0.5))\n",
        "    new_X_test.append(torch.reshape(a, (10, 20)))\n",
        "\n",
        "new_y_test=[]\n",
        "for seq in y_test:\n",
        "    new_y_test.append(torch.tensor(seq))"
      ],
      "metadata": {
        "id": "lZ_njrYUF8xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HltJ0LUTguJ"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "698TlmaywBez"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "class QSAL_qiskit(torch.nn.Module):\n",
        "    def __init__(self,S,n,Denc,D):\n",
        "        \"\"\"\n",
        "        # input: input data\n",
        "        # weight: trainable parameter\n",
        "        # n: # of of qubits\n",
        "        # d: embedding dimension which is equal to n(Denc+2)\n",
        "        # Denc: the # number of layers for encoding \n",
        "        # D: the # of layers of variational layers\n",
        "        # type \"K\": key, \"Q\": Query, \"V\": value\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.seq_num=S\n",
        "        self.init_params_Q=torch.nn.Parameter(torch.stack([(np.pi/4) * (2 * torch.randn(n*(D+2)) - 1) for _ in range(self.seq_num)]))\n",
        "        self.init_params_K=torch.nn.Parameter(torch.stack([(np.pi/4) * (2 * torch.randn(n*(D+2)) - 1) for _ in range(self.seq_num)]))\n",
        "        self.init_params_V=torch.nn.Parameter(torch.stack([(np.pi/4) * (2 * torch.randn(n*(D+2)) - 1) for _ in range(self.seq_num)]))\n",
        "        self.params_input=[ParameterVector('IN'+str(i),n*(Denc+2)) for i in range(self.seq_num)]\n",
        "        self.params_Q=[ParameterVector('Q'+str(i),n*(D+2)) for i in range(self.seq_num)]\n",
        "        self.params_K=[ParameterVector('K'+str(i),n*(D+2)) for i in range(self.seq_num)]\n",
        "        self.params_V=[ParameterVector('V'+str(i),n*(D+2)) for i in range(self.seq_num)]\n",
        "        self.num_q=n\n",
        "        self.Denc=Denc\n",
        "        self.D=D\n",
        "        self.d=n*(Denc+2)\n",
        "        self.bit_string_Z=SparsePauliOp.from_list([('I'*(self.num_q-1)+'Z', 1)])\n",
        "        self.pauli_strings=[]\n",
        "        for i in range(self.d):\n",
        "            string=['I']*self.num_q\n",
        "            while string==['I']*self.num_q:\n",
        "                for j in range(self.num_q):\n",
        "                    a=random.randint(0, 4)\n",
        "                    if a==0:\n",
        "                        continue\n",
        "                    elif a==1:\n",
        "                        string[j]='X'\n",
        "                    elif a==2:\n",
        "                        string[j]='Y'\n",
        "                    elif a==3:\n",
        "                        string[j]='Z'\n",
        "            self.pauli_strings.append(SparsePauliOp.from_list([(\"\".join(string), 1)]))  \n",
        "\n",
        "        Q_qnn=[EstimatorQNN(circuit=self.QSAL_cir(\"Q\",i),observables=[self.bit_string_Z], input_params=self.params_input[i], weight_params=self.params_Q[i]) for i in range(self.seq_num)]\n",
        "        K_qnn=[EstimatorQNN(circuit=self.QSAL_cir(\"K\",i),observables=[self.bit_string_Z], input_params=self.params_input[i], weight_params=self.params_K[i]) for i in range(self.seq_num)]\n",
        "        V_qnn=[EstimatorQNN(circuit=self.QSAL_cir(\"V\",i),observables=self.pauli_strings, input_params=self.params_input[i], weight_params=self.params_V[i]) for i in range(self.seq_num)]\n",
        "\n",
        "        self.Q_models=[TorchConnector(Q_qnn[i], initial_weights=self.init_params_Q[i]) for i in range(self.seq_num)]\n",
        "        self.K_models=[TorchConnector(K_qnn[i], initial_weights=self.init_params_K[i]) for i in range(self.seq_num)]\n",
        "        self.V_models=[TorchConnector(V_qnn[i], initial_weights=self.init_params_V[i]) for i in range(self.seq_num)]\n",
        "\n",
        "    def QSAL_cir(self,type,indx):\n",
        "\n",
        "        qc=QuantumCircuit(self.num_q)  \n",
        "        if type==\"Q\":\n",
        "            self.Feature_map(qc,self.params_input[indx])\n",
        "            self.ansatz(qc,self.params_Q[indx])\n",
        "            \n",
        "        elif type==\"K\":\n",
        "            self.Feature_map(qc,self.params_input[indx])\n",
        "            self.ansatz(qc,self.params_K[indx])\n",
        "\n",
        "        elif type==\"V\":\n",
        "            self.Feature_map(qc,self.params_input[indx])\n",
        "            self.ansatz(qc,self.params_V[indx])\n",
        "\n",
        "        return qc\n",
        "\n",
        "    def Feature_map(self,qc,params):\n",
        "        indx=0\n",
        "        for j in range(self.num_q):\n",
        "            qc.rx(params[indx],j)\n",
        "            qc.ry(params[indx+1],j)\n",
        "            indx+=2\n",
        "        for i in range(self.Denc):\n",
        "            for j in range(self.num_q):\n",
        "                qc.cx(j,(j+1)%self.num_q)\n",
        "\n",
        "            for j in range(self.num_q):\n",
        "                #qc.rx(params[indx],j)\n",
        "                qc.ry(params[indx],j)\n",
        "                indx+=1\n",
        "            \n",
        "\n",
        "    def ansatz(self,qc,params):\n",
        "        indx=0\n",
        "        for j in range(self.num_q):\n",
        "            qc.rx(params[indx],j)\n",
        "            qc.ry(params[indx+1],j)\n",
        "            indx+=2\n",
        "        for i in range(self.D):\n",
        "            for j in range(self.num_q):\n",
        "                qc.cx(j,(j+1)%self.num_q)\n",
        "                \n",
        "            for j in range(self.num_q):\n",
        "                #qc.rx(params[indx],j)\n",
        "                qc.ry(params[indx],j)\n",
        "                indx+=1\n",
        "\n",
        "    def forward(self,input):\n",
        "\n",
        "        Q_output=torch.stack([self.Q_models[i](input[:,i]) for i in range(self.seq_num)])\n",
        "        K_output=torch.stack([self.K_models[i](input[:,i]) for i in range(self.seq_num)])\n",
        "        V_output=torch.stack([self.V_models[i](input[:,i]) for i in range(self.seq_num)])\n",
        "        batch_size=len(input)\n",
        "        Q_output=Q_output.transpose(0,2).repeat((self.seq_num,1,1))\n",
        "        K_output=K_output.transpose(0,2).repeat((self.seq_num,1,1)).transpose(0,2)\n",
        "        #print(V_output.size())\n",
        "        #Q_grid, K_grid=torch.meshgrid(Q_output, K_output, indexing='ij')\n",
        "        alpha=torch.exp(-(Q_output-K_output)**2)\n",
        "        alpha=alpha.transpose(0,1)\n",
        "        V_output=V_output.transpose(0,1)\n",
        "        output=[]\n",
        "\n",
        "        for i in range(self.seq_num):\n",
        "            \n",
        "            Sum_a=torch.sum(alpha[:,i,:],-1)\n",
        "            div_sum_a=(1/Sum_a).repeat(self.d,self.seq_num,1).transpose(0,2)\n",
        "            \n",
        "            Sum_w=torch.sum(alpha[:,:,i].repeat((self.d,1,1)).transpose(0,2).transpose(0,1)*V_output*div_sum_a,1)\n",
        "            output.append(Sum_w)\n",
        "        return input+torch.stack(output).transpose(0,1)\n",
        "\n",
        "\n",
        "class QSANN_qiskit(torch.nn.Module):\n",
        "    def __init__(self,S,n,Denc,D,num_layers):\n",
        "        \"\"\"\n",
        "        # input: input data\n",
        "        # weight: trainable parameter\n",
        "        # n: # of of qubits\n",
        "        # d: embedding dimension which is equal to n(Denc+2)\n",
        "        # Denc: the # number of layers for encoding \n",
        "        # D: the # of layers of variational layers\n",
        "        # type \"K\": key, \"Q\": Query, \"V\": value\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.qsal_lst=[QSAL_qiskit(S,n,Denc,D) for _ in range(num_layers)]\n",
        "        self.qnn=nn.Sequential(*self.qsal_lst)\n",
        "\n",
        "    def forward(self,input):\n",
        "\n",
        "        return self.qnn(input)\n",
        "        \n",
        "class QSANN_text_classifier(torch.nn.Module):\n",
        "    def __init__(self,S,n,Denc,D,num_layers):\n",
        "        \"\"\"\n",
        "        # input: input data\n",
        "        # weight: trainable parameter\n",
        "        # n: # of of qubits\n",
        "        # d: embedding dimension which is equal to n(Denc+2)\n",
        "        # Denc: the # number of layers for encoding \n",
        "        # D: the # of layers of variational layers\n",
        "        # type \"K\": key, \"Q\": Query, \"V\": value\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.Qnn=QSANN_qiskit(S,n,Denc,D,num_layers)\n",
        "        self.final_layer=nn.Linear(n*(Denc+2)*S, 1)\n",
        "        self.final_layer=self.final_layer.float()\n",
        "\n",
        "    def forward(self,input):\n",
        "\n",
        "        x=self.Qnn(input)\n",
        "        x=torch.flatten(x,start_dim=1)\n",
        "        \n",
        "        return torch.sigmoid(self.final_layer(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrpAs8jtTaFZ"
      },
      "source": [
        "# Training (Random Toy data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jq8UNdVUw_Le"
      },
      "outputs": [],
      "source": [
        "X=[[np.array([random.random() for _ in range(6)]) for _ in range(5)] for _ in range(32)]\n",
        "Y=[random.randint(0,1) for _ in range(32)]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=QSANN_text_classifier(5,2,1,1,1)"
      ],
      "metadata": {
        "id": "tuCZzry8kOYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh37yKTMzj5a"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(lr=0.03, params=model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6KcogR3jsTa",
        "outputId": "f978e49f-624b-4238-8242-16ab0d4e3e46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "481\n"
          ]
        }
      ],
      "source": [
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(trainable_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdfOa7F13aCY"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOyQmYRB94v3"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = (torch.round(torch.sign(preds-0.5))+1)//2\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R41mLS_C4dK_",
        "outputId": "ed7ebde0-f980-4f86-9728-9cb415a77c37"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]<ipython-input-16-5cfb7c505ff2>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  X_tensor=torch.tensor(X)\n",
            "100%|██████████| 10/10 [05:23<00:00, 32.31s/it]\n"
          ]
        }
      ],
      "source": [
        "for iepoch in tqdm(range(10)):\n",
        "    optimizer.zero_grad()\n",
        "    X_tensor=torch.tensor(X)\n",
        "    predictions=model(X_tensor.float()).squeeze(1)\n",
        "    #predictions=torch.sign(predictions)\n",
        "    label=torch.tensor(Y)\n",
        "    loss = criterion(predictions, label.float())\n",
        "    acc = binary_accuracy(predictions, label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    #print(acc)\n",
        "    #print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngz-jQAtryQn"
      },
      "source": [
        "# Train Real Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivig6keChfN9"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = (torch.round(torch.sign(preds-0.5))+1)//2\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3yLEdEfrx4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a81975-917b-4406-b674-f33b5714554b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/qiskit_machine_learning/connectors/torch_connector.py:312: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self._weights.data = torch.tensor(initial_weights, dtype=torch.float)\n"
          ]
        }
      ],
      "source": [
        "model = QSANN_text_classifier(10,2,8,1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TO6LB7BUAMG_"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(lr=0.005, params=model.parameters())\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnAE4Pf00TWK",
        "outputId": "cf5ffac8-f2be-4acd-bb27-cc49e75f1a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "381\n"
          ]
        }
      ],
      "source": [
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(trainable_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZzMfXH-xfoi",
        "outputId": "f390164d-a235-4329-f263-01cd492be8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/40 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5938)\n",
            "\n",
            "tensor(44.9861, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▎         | 1/40 [08:25<5:28:46, 505.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5312)\n",
            "\n",
            "tensor(52.1053, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 2/40 [16:51<5:20:16, 505.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5312)\n",
            "\n",
            "tensor(52.1453, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 3/40 [25:16<5:11:34, 505.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.4688)\n",
            "\n",
            "tensor(58.6534, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 4/40 [33:54<5:06:08, 510.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5625)\n",
            "\n",
            "tensor(48.3179, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 5/40 [42:25<4:57:59, 510.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6250)\n",
            "\n",
            "tensor(41.3506, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 6/40 [50:57<4:49:38, 511.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6250)\n",
            "\n",
            "tensor(44.9576, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 7/40 [59:21<4:39:44, 508.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6250)\n",
            "\n",
            "tensor(55.0827, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 8/40 [1:07:47<4:30:48, 507.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5312)\n",
            "\n",
            "tensor(58.6790, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▎       | 9/40 [1:16:09<4:21:25, 505.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5625)\n",
            "\n",
            "tensor(62.1335, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 10/40 [1:24:33<4:12:44, 505.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5625)\n",
            "\n",
            "tensor(58.2181, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 11/40 [1:32:57<4:04:03, 504.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6250)\n",
            "\n",
            "tensor(68.8063, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 12/40 [1:41:12<3:54:20, 502.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5938)\n",
            "\n",
            "tensor(65.5190, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▎      | 13/40 [1:49:34<3:45:51, 501.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5625)\n",
            "\n",
            "tensor(58.1260, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 14/40 [1:58:01<3:38:09, 503.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6562)\n",
            "\n",
            "tensor(54.5875, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 15/40 [2:06:23<3:29:37, 503.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6250)\n",
            "\n",
            "tensor(61.8215, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 16/40 [2:14:52<3:21:58, 504.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8438)\n",
            "\n",
            "tensor(57.7704, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▎     | 17/40 [2:23:22<3:14:03, 506.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6250)\n",
            "\n",
            "tensor(57.9020, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 18/40 [2:32:03<3:07:19, 510.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6562)\n",
            "\n",
            "tensor(47.7124, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 19/40 [2:40:37<2:59:08, 511.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6250)\n",
            "\n",
            "tensor(47.3433, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 20/40 [2:49:06<2:50:19, 510.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6875)\n",
            "\n",
            "tensor(47.3137, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▎    | 21/40 [2:57:33<2:41:26, 509.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7188)\n",
            "\n",
            "tensor(54.4230, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 22/40 [3:06:12<2:33:45, 512.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8125)\n",
            "\n",
            "tensor(46.7288, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▊    | 23/40 [3:14:46<2:25:17, 512.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6875)\n",
            "\n",
            "tensor(65.0209, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 24/40 [3:23:16<2:16:34, 512.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.5938)\n",
            "\n",
            "tensor(43.6737, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 25/40 [3:31:47<2:07:53, 511.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6875)\n",
            "\n",
            "tensor(54.1294, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 26/40 [3:40:22<1:59:36, 512.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6250)\n",
            "\n",
            "tensor(65.1941, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 27/40 [3:48:52<1:50:55, 511.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7500)\n",
            "\n",
            "tensor(47.1497, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 28/40 [3:57:32<1:42:51, 514.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8438)\n",
            "\n",
            "tensor(50.2648, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▎  | 29/40 [4:06:02<1:34:03, 513.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.6562)\n",
            "\n",
            "tensor(50.7554, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 30/40 [4:14:42<1:25:52, 515.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7500)\n",
            "\n",
            "tensor(71.3122, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 31/40 [4:23:15<1:17:09, 514.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7500)\n",
            "\n",
            "tensor(57.3172, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 32/40 [4:31:50<1:08:36, 514.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7812)\n",
            "\n",
            "tensor(46.7539, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▎ | 33/40 [4:40:22<59:56, 513.79s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.9062)\n",
            "\n",
            "tensor(50.0969, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 34/40 [4:48:55<51:22, 513.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8125)\n",
            "\n",
            "tensor(36.2328, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 35/40 [4:57:26<42:44, 512.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7500)\n",
            "\n",
            "tensor(32.8583, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 36/40 [5:05:58<34:10, 512.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7500)\n",
            "\n",
            "tensor(43.0760, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▎| 37/40 [5:14:23<25:30, 510.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7812)\n",
            "\n",
            "tensor(50.3383, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 38/40 [5:22:49<16:58, 509.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.8125)\n",
            "\n",
            "tensor(53.7304, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 39/40 [5:31:19<08:29, 509.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7812)\n",
            "\n",
            "tensor(53.9442, grad_fn=<DivBackward1>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [5:39:59<00:00, 509.98s/it]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for iepoch in tqdm(range(40)):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    idx = torch.randperm(128)[:32]\n",
        "    X_batch = new_X_train[idx]\n",
        "    predictions=model(X_batch.float()).squeeze(1)\n",
        "\n",
        "    label_batch=label[idx]\n",
        "    loss = criterion(predictions, label_batch.float())\n",
        "    acc = binary_accuracy(predictions,label_batch)\n",
        "    print('')\n",
        "    print('Accuracy:',acc)\n",
        "    print('')\n",
        "    print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsCVeF18zFgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e7fc5c-c2e3-41d4-f719-9a6d9f0cd3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.7969)\n",
            "\n",
            "tensor(302.9272, grad_fn=<DivBackward1>)\n"
          ]
        }
      ],
      "source": [
        "X_batch = new_X_train\n",
        "predictions=model(X_batch.float()).squeeze(1)\n",
        "\n",
        "loss = criterion(predictions, label.float())\n",
        "acc = binary_accuracy(predictions,label)\n",
        "print('')\n",
        "print('Accuracy:',acc)\n",
        "print('')\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_test=torch.stack(new_y_test)"
      ],
      "metadata": {
        "id": "V8kPOWu5GOJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G62OVp2Cf0oh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de082f6-835b-403e-919d-13424ee8a85f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: tensor(0.4219)\n",
            "\n",
            "tensor(312.8112, grad_fn=<DivBackward1>)\n"
          ]
        }
      ],
      "source": [
        "X_batch = torch.stack(new_X_test)\n",
        "predictions=model(X_batch.float()).squeeze(1)\n",
        "\n",
        "loss = criterion(predictions, label_test.float())\n",
        "acc = binary_accuracy(predictions,label_test)\n",
        "print('')\n",
        "print('Accuracy:',acc)\n",
        "print('')\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "1F4wVqamK8N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name=path+'QSANN_qiskit_model_1'\n",
        "torch.save(model.state_dict(),file_name)"
      ],
      "metadata": {
        "id": "CTmCQSWIGWel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sI3XQ7qAMQXp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMq5DAj8NMLt",
        "outputId": "cbcea64b-d4c5-47a9-ac87-e9aa3cdcb5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.33.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.11.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.2)\n",
            "Collecting rustworkx (from pennylane)\n",
            "  Downloading rustworkx-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.6.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Collecting semantic-version>=2.7 (from pennylane)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting autoray>=0.6.1 (from pennylane)\n",
            "  Downloading autoray-0.6.7-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.3.2)\n",
            "Collecting pennylane-lightning>=0.33 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.33.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.5.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd->pennylane) (0.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2023.7.22)\n",
            "Installing collected packages: semantic-version, rustworkx, autoray, pennylane-lightning, pennylane\n",
            "Successfully installed autoray-0.6.7 pennylane-0.33.0 pennylane-lightning-0.33.0 rustworkx-0.13.2 semantic-version-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/CQCL/qnlp_lorenz_etal_2021_resources\n",
        "!mv qnlp_lorenz_etal_2021_resources/datasets mc_rp_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWb9ZnDkOCKM",
        "outputId": "32601438-f789-4738-f589-f0fdd615d7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'qnlp_lorenz_etal_2021_resources'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 93 (delta 41), reused 57 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (93/93), 56.79 KiB | 4.73 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from joblib import load, dump\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from collections import Counter\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPuq2dXsOUX7",
        "outputId": "3bd29a4b-3213-4269-b703-dcd1b981e719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-7ff04ebe0c94>:10: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_rp_sets_path = Path(\"mc_rp_dataset\")\n",
        "mc_rp_sets = list(mc_rp_sets_path.glob(\"*.txt\"))\n",
        "mc_datasets, rp_datasets = list(filter(lambda x: x.name.startswith(\"mc\"), mc_rp_sets)), list(filter(lambda x: x.name.startswith(\"rp\"), mc_rp_sets))"
      ],
      "metadata": {
        "id": "69fDeWGjOZu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading MC and RP data and creating data loaders from our data loading strategy\n",
        "def read_process_mcrp(datapaths: dict):\n",
        "  def rm(text):\n",
        "    return \" \".join(list(map(lambda x: x[:x.find('_')], text.split())))\n",
        "  retval = {}\n",
        "  for datapath in datapaths:\n",
        "    if \"rp\" in str(datapath):\n",
        "      sel = 2\n",
        "    else:\n",
        "      sel = 3\n",
        "    df = pd.DataFrame(list(map(lambda x: [int(x[0]), x[sel:]], datapath.read_text().split(\"\\n\"))), columns=['label', 'text'])\n",
        "    df['text'] = df['text'].apply(rm)\n",
        "    retval[datapath.name.split(\".\")[0]] = df\n",
        "  return retval\n",
        "\n",
        "mc_data, rp_data = read_process_mcrp(mc_datasets), read_process_mcrp(rp_datasets)\n",
        "MRP_BATCH_SIZE = 30"
      ],
      "metadata": {
        "id": "jSUU41L-PaL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5nrl-AoM7I6"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import pennylane as qml\n",
        "\n",
        "class MultiHeadAttentionBase(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embed_dim: int,\n",
        "                 num_heads: int,\n",
        "                 dropout: float = 0.1,\n",
        "                 mask=None,\n",
        "                 use_bias=False):\n",
        "        super(MultiHeadAttentionBase, self).__init__()\n",
        "\n",
        "        assert embed_dim % num_heads == 0, f\"Embedding dimension ({embed_dim}) should be divisible by number of heads ({num_heads})\"\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = embed_dim // num_heads  # projection dimensions\n",
        "        self.k_linear = None\n",
        "        self.q_linear = None\n",
        "        self.v_linear = None\n",
        "        self.combine_heads = None\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.attn_weights = None\n",
        "\n",
        "    def separate_heads(self, x):\n",
        "        '''\n",
        "        split into N heads\n",
        "        from (batch_size, seq_len, embed_dim)\n",
        "        to   (batch_size, seq_len, num_heads, embed_dim)\n",
        "        then transpose (1,2) to (batch_size, num_heads, seq_len, embed_dim)\n",
        "        to make mat mult straightforward for each head\n",
        "        '''\n",
        "        batch_size = x.size(0)\n",
        "        x = x.view(batch_size, -1, self.num_heads, self.d_k)\n",
        "        return x.transpose(1, 2)\n",
        "\n",
        "    def attention(self, query, key, value, mask=None, dropout=None):\n",
        "        '''\n",
        "        Attention(Q, K, V) = softmax(Q K^T / sqrt(d_k))V\n",
        "        '''\n",
        "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        # see also: https://tensorchiefs.github.io/dlday2018/tutorial/einsum.html\n",
        "        #scores = torch.einsum('bijh, bkjh -> bikh', query, key) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1)\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        scores = F.softmax(scores, dim=-1)\n",
        "        if dropout is not None:\n",
        "            scores = dropout(scores)\n",
        "        attn = torch.matmul(scores, value)\n",
        "        return attn, scores\n",
        "\n",
        "    def downstream(self, query, key, value, batch_size, mask=None):\n",
        "        Q = self.separate_heads(query)\n",
        "        K = self.separate_heads(key)\n",
        "        V = self.separate_heads(value)\n",
        "\n",
        "        x, self.attn_weights = self.attention(Q, K, V, mask, dropout=self.dropout)\n",
        "\n",
        "        concat = x.transpose(1, 2).contiguous().view(batch_size, -1, self.embed_dim)\n",
        "\n",
        "        return concat\n",
        "        # output = self.combine_heads(concat)\n",
        "        # return output\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        raise NotImplementedError(\"Base class does not execute forward function.\")\n",
        "\n",
        "\n",
        "class MultiHeadAttentionClassical(MultiHeadAttentionBase):\n",
        "    def __init__(self, embed_dim: int,\n",
        "                 num_heads: int,\n",
        "                 dropout=0.1,\n",
        "                 mask=None,\n",
        "                 use_bias=False):\n",
        "        super(MultiHeadAttentionClassical, self).__init__(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout, mask=mask, use_bias=use_bias)\n",
        "\n",
        "        self.k_linear = nn.Linear(embed_dim, embed_dim, bias=use_bias)\n",
        "        self.q_linear = nn.Linear(embed_dim, embed_dim, bias=use_bias)\n",
        "        self.v_linear = nn.Linear(embed_dim, embed_dim, bias=use_bias)\n",
        "        self.combine_heads = nn.Linear(embed_dim, embed_dim, bias=use_bias)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, embed_dim = x.size()\n",
        "        assert embed_dim == self.embed_dim, f\"Input embedding ({embed_dim}) does not match layer embedding size ({self.embed_dim})\"\n",
        "\n",
        "        K = self.k_linear(x)\n",
        "        Q = self.q_linear(x)\n",
        "        V = self.v_linear(x)\n",
        "\n",
        "        x = self.downstream(Q, K, V, batch_size, mask)\n",
        "        output = self.combine_heads(x)\n",
        "        return output\n",
        "\n",
        "\n",
        "class MultiHeadAttentionQuantum(MultiHeadAttentionBase):\n",
        "    def __init__(self,\n",
        "                 embed_dim: int,\n",
        "                 num_heads: int,\n",
        "                 dropout=0.1,\n",
        "                 mask=None,\n",
        "                 use_bias=False,\n",
        "                 n_qubits: int = 4,\n",
        "                 n_qlayers: int = 1,\n",
        "                 q_device=\"default.qubit\"):\n",
        "        super(MultiHeadAttentionQuantum, self).__init__(embed_dim, num_heads, dropout=dropout, mask=mask, use_bias=use_bias)\n",
        "\n",
        "        # todo: add intermediate layer to \"dress\" quantum circuit\n",
        "        assert n_qubits == embed_dim, \"Number of qubits ({n_qubits}) does not match embedding dim ({embed_dim})\"\n",
        "\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_qlayers = n_qlayers\n",
        "        self.q_device = q_device\n",
        "        if 'qulacs' in q_device:\n",
        "            self.dev = qml.device(q_device, wires=self.n_qubits, gpu=True)\n",
        "        elif 'braket' in q_device:\n",
        "            self.dev = qml.device(q_device, wires=self.n_qubits, parallel=True)\n",
        "        else:\n",
        "            self.dev = qml.device(q_device, wires=self.n_qubits)\n",
        "\n",
        "        def _circuit(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=range(self.n_qubits))\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "            return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
        "\n",
        "        self.qlayer = qml.QNode(_circuit, self.dev, interface=\"torch\")\n",
        "        self.weight_shapes = {\"weights\": (n_qlayers, n_qubits)}\n",
        "        print(f\"weight_shapes = (n_qlayers, n_qubits) = ({n_qlayers}, {self.n_qubits})\")\n",
        "\n",
        "        self.k_linear = qml.qnn.TorchLayer(self.qlayer, self.weight_shapes)\n",
        "        self.q_linear = qml.qnn.TorchLayer(self.qlayer, self.weight_shapes)\n",
        "        self.v_linear = qml.qnn.TorchLayer(self.qlayer, self.weight_shapes)\n",
        "        self.combine_heads = qml.qnn.TorchLayer(self.qlayer, self.weight_shapes)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, embed_dim = x.size()\n",
        "        assert embed_dim == self.embed_dim, f\"Input embedding ({embed_dim}) does not match layer embedding size ({self.embed_dim})\"\n",
        "\n",
        "        K = [self.k_linear(x[:, t, :]) for t in range(seq_len)]\n",
        "        Q = [self.q_linear(x[:, t, :]) for t in range(seq_len)]\n",
        "        V = [self.v_linear(x[:, t, :]) for t in range(seq_len)]\n",
        "\n",
        "        K = torch.Tensor(pad_sequence(K))\n",
        "        Q = torch.Tensor(pad_sequence(Q))\n",
        "        V = torch.Tensor(pad_sequence(V))\n",
        "\n",
        "        x = self.downstream(Q, K, V, batch_size, mask)\n",
        "        output = [self.combine_heads(x[:, t, :]) for t in range(seq_len)]\n",
        "        output = torch.Tensor(pad_sequence(output))\n",
        "        return output\n",
        "\n",
        "\n",
        "class FeedForwardBase(nn.Module):\n",
        "    def __init__(self, embed_dim, ffn_dim, dropout=0.1):\n",
        "        super(FeedForwardBase, self).__init__()\n",
        "        self.linear_1 = nn.Linear(embed_dim, ffn_dim)\n",
        "        self.linear_2 = nn.Linear(ffn_dim, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError(\"Base class does not implement forward function\")\n",
        "\n",
        "\n",
        "class FeedForwardClassical(FeedForwardBase):\n",
        "    def __init__(self, embed_dim, ffn_dim, dropout=0.1):\n",
        "        super(FeedForwardClassical, self).__init__(embed_dim, ffn_dim, dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear_1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear_2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class FeedForwardQuantum(FeedForwardBase):\n",
        "    def __init__(self, embed_dim, n_qubits, n_qlayers=1, dropout=0.1, q_device=\"default.qubit\"):\n",
        "        super(FeedForwardQuantum, self).__init__(embed_dim, ffn_dim=n_qubits, dropout=dropout)\n",
        "\n",
        "        self.n_qubits = n_qubits\n",
        "        if 'qulacs' in q_device:\n",
        "            self.dev = qml.device(q_device, wires=self.n_qubits, gpu=True)\n",
        "        elif 'braket' in q_device:\n",
        "            self.dev = qml.device(q_device, wires=self.n_qubits, parallel=True)\n",
        "        else:\n",
        "            self.dev = qml.device(q_device, wires=self.n_qubits)\n",
        "\n",
        "        def _circuit(inputs, weights):\n",
        "            qml.templates.AngleEmbedding(inputs, wires=range(self.n_qubits))\n",
        "            qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "            return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
        "        self.qlayer = qml.QNode(_circuit, self.dev, interface=\"torch\")\n",
        "        self.weight_shapes = {\"weights\": (n_qlayers, n_qubits)}\n",
        "        self.vqc = qml.qnn.TorchLayer(self.qlayer, self.weight_shapes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "        x = self.linear_1(x)\n",
        "        X = [self.vqc(x[:, t, :]) for t in range(seq_len)]\n",
        "        x = torch.Tensor(pad_sequence(X))\n",
        "        # dropout?\n",
        "        x = self.linear_2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerBlockBase(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embed_dim: int,\n",
        "                 num_head: int,\n",
        "                 ff_dim: int,\n",
        "                 n_qubits_transformer: int = 0,\n",
        "                 n_qubits_ffn: int = 0,\n",
        "                 n_qlayers: int = 1,\n",
        "                 dropout: float = 0.1,\n",
        "                 mask=None):\n",
        "        super(TransformerBlockBase, self).__init__()\n",
        "        self.attn = None\n",
        "        self.ffn = None\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output = self.attn(x)\n",
        "        x = self.norm1(attn_output + x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        ff_output = self.ffn(x)\n",
        "        x = self.norm2(ff_output + x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerBlockClassical(TransformerBlockBase):\n",
        "    def __init__(self,\n",
        "                 embed_dim: int,\n",
        "                 num_heads: int,\n",
        "                 ff_dim: int,\n",
        "                 dropout: float = 0.1,\n",
        "                 mask=None):\n",
        "        super(TransformerBlockClassical, self).__init__(embed_dim, num_heads, ff_dim, dropout, mask)\n",
        "        self.attn = MultiHeadAttentionClassical(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout, mask=mask)\n",
        "        self.ffn = FeedForwardClassical(embed_dim, ff_dim)\n",
        "\n",
        "\n",
        "class TransformerBlockQuantum(TransformerBlockBase):\n",
        "    def __init__(self,\n",
        "                 embed_dim: int,\n",
        "                 num_heads: int,\n",
        "                 ffn_dim: int,\n",
        "                 n_qubits_transformer: int = 0,\n",
        "                 n_qubits_ffn: int = 0,\n",
        "                 n_qlayers: int = 1,\n",
        "                 dropout: float = 0.1,\n",
        "                 mask=None,\n",
        "                 q_device='default.qubit'):\n",
        "        super(TransformerBlockQuantum, self).__init__(embed_dim, num_heads, ffn_dim, dropout, mask)\n",
        "\n",
        "        self.n_qubits_transformer = n_qubits_transformer\n",
        "        self.n_qubits_ffn = n_qubits_ffn\n",
        "        self.n_qlayers = n_qlayers\n",
        "\n",
        "        self.attn = MultiHeadAttentionQuantum(embed_dim,\n",
        "                                              num_heads,\n",
        "                                              n_qubits=n_qubits_transformer,\n",
        "                                              n_qlayers=n_qlayers,\n",
        "                                              dropout=dropout,\n",
        "                                              mask=mask,\n",
        "                                              q_device=q_device)\n",
        "        if n_qubits_ffn > 0:\n",
        "            self.ffn = FeedForwardQuantum(embed_dim, n_qubits_ffn, n_qlayers, q_device=q_device)\n",
        "        else:\n",
        "            self.ffn = FeedForwardClassical(embed_dim, ffn_dim)\n",
        "\n",
        "\n",
        "class PositionalEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim, max_seq_len=512):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # create constant 'pe' matrix with values dependant on pos and i\n",
        "        pe = torch.zeros(max_seq_len, embed_dim)\n",
        "        for pos in range(max_seq_len):\n",
        "            for i in range(0, embed_dim, 2):\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/embed_dim)))\n",
        "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/embed_dim)))\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # make embeddings relatively larger\n",
        "        x = x * math.sqrt(self.embed_dim)\n",
        "        #add constant to embedding\n",
        "        seq_len = x.size(1)\n",
        "        x = x + torch.autograd.Variable(self.pe[:,:seq_len], requires_grad=False)  # .cuda()\n",
        "        return x\n",
        "\n",
        "\n",
        "class TextClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 embed_dim: int,\n",
        "                 num_heads: int,\n",
        "                 num_blocks: int,\n",
        "                 num_classes: int,\n",
        "                 vocab_size: int,\n",
        "                 ffn_dim: int = 32,\n",
        "                 n_qubits_transformer: int = 0,\n",
        "                 n_qubits_ffn: int = 0,\n",
        "                 n_qlayers: int = 0,\n",
        "                 dropout=0.1,\n",
        "                 q_device=\"device.qubit\"):\n",
        "        super(TextClassifier, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.num_blocks = num_blocks\n",
        "        self.num_classes = num_classes\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.pos_embedding = PositionalEncoder(embed_dim)\n",
        "\n",
        "        print(f\"++ There will be {num_blocks} transformer blocks\")\n",
        "\n",
        "        if n_qubits_transformer > 0:\n",
        "            print(f\"++ Transformer will use {n_qubits_transformer} qubits and {n_qlayers} q layers\")\n",
        "            if n_qubits_ffn > 0:\n",
        "                print(f\"The feed-forward head will use {n_qubits_ffn} qubits\")\n",
        "            else:\n",
        "                print(f\"The feed-forward head will be classical\")\n",
        "            print(f\"Using quantum device {q_device}\")\n",
        "\n",
        "            transformer_blocks = [\n",
        "                TransformerBlockQuantum(embed_dim, num_heads, ffn_dim,\n",
        "                                        n_qubits_transformer=n_qubits_transformer,\n",
        "                                        n_qubits_ffn=n_qubits_ffn,\n",
        "                                        n_qlayers=n_qlayers,\n",
        "                                        q_device=q_device) for _ in range(num_blocks)\n",
        "            ]\n",
        "        else:\n",
        "            transformer_blocks = [\n",
        "                TransformerBlockClassical(embed_dim, num_heads, ffn_dim) for _ in range(num_blocks)\n",
        "            ]\n",
        "\n",
        "        self.transformers = nn.Sequential(*transformer_blocks)\n",
        "        if self.num_classes > 2:\n",
        "            self.class_logits = nn.Linear(embed_dim, num_classes)\n",
        "        else:\n",
        "            self.class_logits = nn.Linear(embed_dim, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size=x.shape[0]\n",
        "        tokens = self.token_embedding(x)\n",
        "        # batch_size, seq_len, embed_dim = x.size()\n",
        "        x = self.pos_embedding(tokens)\n",
        "        x = self.transformers(x)\n",
        "        x = x.mean(dim=1)  # global average pooling, works in 1D\n",
        "        x = self.dropout(x)\n",
        "        x = self.class_logits(x)\n",
        "        # return F.log_softmax(x, dim=1)\n",
        "        return torch.sigmoid(x).reshape(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_frame_simple_txt2vec(data,keystr,min_length=6,w_dict=None): # Just label the words based on how often they show in the text\n",
        "    txt_lst=[]\n",
        "    max_len=0\n",
        "    for txt in data[keystr].text:\n",
        "        txtsplit=txt.split()\n",
        "        txt_lst=txt_lst+txtsplit\n",
        "        if max_len< len(txtsplit):\n",
        "            max_len=len(txtsplit)\n",
        "    w_set=set(txt_lst)\n",
        "\n",
        "    comm_lst=Counter(txt_lst).most_common()\n",
        "\n",
        "    if w_dict==None:\n",
        "        w_dict={}\n",
        "        ind=len(comm_lst)\n",
        "        for elem in comm_lst:\n",
        "            w_dict[elem[0]]=ind\n",
        "            ind-=1\n",
        "    #w_dict={}\n",
        "    #ind=1\n",
        "    #for elem in w_set:\n",
        "    #    w_dict[elem]=ind\n",
        "    #    ind+=1\n",
        "\n",
        "    if max_len%2 !=0:\n",
        "        max_len+=1\n",
        "    if max_len<min_length:\n",
        "        max_len=min_length\n",
        "\n",
        "    label_list=[]\n",
        "    Txt_list=[]\n",
        "    for i, txt in enumerate(data[keystr].text):\n",
        "        w_list=[]\n",
        "        for word in data[keystr].text[i].split():\n",
        "            if word in w_dict:\n",
        "                w_list.append(w_dict[word])\n",
        "            else:\n",
        "                w_list.append(len(w_dict.keys())+1)\n",
        "        if len(w_list) < max_len:\n",
        "            w_list=w_list+(max_len-len(w_list))*[0]\n",
        "        #print(torch.tensor(w_list))\n",
        "        label_list.append(torch.tensor(data[keystr].label[i]))\n",
        "        Txt_list.append(torch.tensor(w_list))\n",
        "    label_tensor=torch.tensor(label_list)\n",
        "    txt_tensor=torch.stack(Txt_list)\n",
        "\n",
        "    return data_utils.TensorDataset(txt_tensor,label_tensor),w_dict"
      ],
      "metadata": {
        "id": "WKMO--gIONbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "mc_df_train,train_dict=data_frame_simple_txt2vec(mc_data,'mc_train_data')\n",
        "mc_df_test,_=data_frame_simple_txt2vec(mc_data,'mc_test_data',w_dict=train_dict)\n",
        "\n",
        "mc_trainloader = DataLoader(mc_df_train, shuffle=True, batch_size=MRP_BATCH_SIZE)\n",
        "mc_testloader = DataLoader(mc_df_test, shuffle=True, batch_size=30)"
      ],
      "metadata": {
        "id": "l2uhLcKLPVn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#embed_dim: int,num_head: int, ff_dim: int,\n",
        "model=TextClassifier(12,6,1,2,20,ffn_dim=8).to(device)\n",
        "num_epochs = 180\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b71WeW0RPg7b",
        "outputId": "a266164c-e3d4-419e-8e67-5b55a7c33549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++ There will be 1 transformer blocks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E79zUOoGQIkn",
        "outputId": "29450cad-2e49-4939-ac7c-74c5938d3196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = (torch.round(torch.sign(preds-0.5))+1)//2\n",
        "    correct = (rounded_preds == y).float() #convert into float for division\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "agaw09BAQMYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS=180\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "train_loss_history=[]\n",
        "train_accuracy_history=[]\n",
        "criterion = torch.nn.BCELoss()\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = []\n",
        "    acc=0\n",
        "    total_len=0\n",
        "    for batch in tqdm(mc_trainloader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float())\n",
        "\n",
        "        train_loss.append(loss.detach().cpu().item()) # len(images)\n",
        "        total_len += len(images)\n",
        "\n",
        "        acc+=binary_accuracy(outputs, labels)*len(images)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    accuracy =  acc / total_len\n",
        "    train_loss_history.append(np.mean(train_loss))\n",
        "    train_accuracy_history.append(accuracy)\n",
        "    print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {np.mean(train_loss):.2f} accuracy:{accuracy}\")\n",
        "    total_len=0\n",
        "    acc1=0\n",
        "    for batch in tqdm(mc_testloader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float())\n",
        "\n",
        "        train_loss.append(loss.detach().cpu().item()) # len(images)\n",
        "        total_len += len(images)\n",
        "\n",
        "        acc1+=binary_accuracy(outputs, labels)*len(images)\n",
        "    acc1 =  acc1 / total_len\n",
        "\n",
        "    print('Testing Accuracy:', acc1)\n",
        "    #Test_acc.append(acc1)"
      ],
      "metadata": {
        "id": "KYOLg5jFQOwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rp_df_train,train_dict=data_frame_simple_txt2vec(rp_data,'rp_train_data')\n",
        "rp_df_test,_=data_frame_simple_txt2vec(rp_data,'rp_test_data',w_dict=train_dict)\n",
        "\n",
        "rp_trainloader = DataLoader(rp_df_train, shuffle=True, batch_size=MRP_BATCH_SIZE)\n",
        "rp_testloader = DataLoader(rp_df_test, shuffle=True, batch_size=30)"
      ],
      "metadata": {
        "id": "W5nlwIFBQTEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#embed_dim: int,num_head: int, ff_dim: int,\n",
        "model=TextClassifier(12,6,1,2,100,ffn_dim=8).to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIa93ZKEUanl",
        "outputId": "f4f50c79-b0de-44ee-e76f-f9e85f091326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++ There will be 1 transformer blocks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5R-J4V5UgHM",
        "outputId": "f032b57d-536f-4204-bb0e-14a4ccaa24c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS=300\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "train_loss_history=[]\n",
        "train_accuracy_history=[]\n",
        "criterion = torch.nn.BCELoss()\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = []\n",
        "    acc=0\n",
        "    total_len=0\n",
        "    for batch in tqdm(rp_trainloader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float())\n",
        "\n",
        "        train_loss.append(loss.detach().cpu().item()) # len(images)\n",
        "        total_len += len(images)\n",
        "\n",
        "        acc+=binary_accuracy(outputs, labels)*len(images)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    accuracy =  acc / total_len\n",
        "    train_loss_history.append(np.mean(train_loss))\n",
        "    train_accuracy_history.append(accuracy)\n",
        "    print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {np.mean(train_loss):.2f} accuracy:{accuracy}\")\n",
        "    total_len=0\n",
        "    acc1=0\n",
        "    for batch in tqdm(rp_testloader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float())\n",
        "\n",
        "        train_loss.append(loss.detach().cpu().item()) # len(images)\n",
        "        total_len += len(images)\n",
        "\n",
        "        acc1+=binary_accuracy(outputs, labels)*len(images)\n",
        "    acc1 =  acc1 / total_len\n",
        "\n",
        "    print('Testing Accuracy:', acc1)\n",
        "    #Test_acc.append(acc1)"
      ],
      "metadata": {
        "id": "JPPmqXY6UldT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/static/public/331/sentiment+labelled+sentences.zip\n",
        "!unzip -o sentiment+labelled+sentences.zip\n",
        "!rm \"sentiment labelled sentences/readme.txt\""
      ],
      "metadata": {
        "id": "0hLVYlmSUtZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67eb704c-964b-4465-dc45-325a91dfc311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-01 14:30:55--  https://archive.ics.uci.edu/static/public/331/sentiment+labelled+sentences.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘sentiment+labelled+sentences.zip’\n",
            "\n",
            "\r          sentiment     [<=>                 ]       0  --.-KB/s               \rsentiment+labelled+     [ <=>                ]  82.21K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-11-01 14:30:55 (1.02 MB/s) - ‘sentiment+labelled+sentences.zip’ saved [84188]\n",
            "\n",
            "Archive:  sentiment+labelled+sentences.zip\n",
            "   creating: sentiment labelled sentences/\n",
            "  inflating: sentiment labelled sentences/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/sentiment labelled sentences/\n",
            "  inflating: __MACOSX/sentiment labelled sentences/._.DS_Store  \n",
            "  inflating: sentiment labelled sentences/amazon_cells_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/imdb_labelled.txt  \n",
            "  inflating: __MACOSX/sentiment labelled sentences/._imdb_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/readme.txt  \n",
            "  inflating: __MACOSX/sentiment labelled sentences/._readme.txt  \n",
            "  inflating: sentiment labelled sentences/yelp_labelled.txt  \n",
            "  inflating: __MACOSX/._sentiment labelled sentences  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating Amazon, IMDb, Yelp dataset paths\n",
        "datasets_path = Path(\"sentiment labelled sentences\")\n",
        "datasets = list(datasets_path.glob(\"*.txt\"))\n",
        "\n",
        "# Reading all data and creating data loaders from our data loading strategy\n",
        "def read_process(datapaths: list):\n",
        "    retval = {}\n",
        "    for datapath in datapaths:\n",
        "        df = pd.DataFrame(list(map(lambda x: x.split(\"\\t\"), datapath.read_text().split(\"\\n\"))), columns=['text', 'label']).dropna()\n",
        "        df['label'] = df['label'].apply(lambda  x: int(x))\n",
        "        retval[datapath.name.split(\".\")[0]] = df\n",
        "    return retval\n",
        "\n",
        "def ttsplit(data: pd.DataFrame, test_size=0.2):\n",
        "    train_data, test_data = train_test_split(data, test_size=test_size, stratify=data['label'], random_state=42)\n",
        "    train_data, test_data = train_data.reset_index().drop(columns=['index']), test_data.reset_index().drop(columns=['index'])\n",
        "    # train_data = pd.DataFrame({'text': X_train, 'labels': y_train})\n",
        "    # test_data = pd.DataFrame({'text': X_test, 'labels': y_test})\n",
        "    return train_data, test_data\n",
        "\n",
        "\n",
        "\n",
        "datadict = read_process(datasets)\n",
        "amazon_data = datadict['amazon_cells_labelled']\n",
        "imdb_data = datadict['imdb_labelled']\n",
        "yelp_data = datadict['yelp_labelled']\n",
        "\n",
        "amazon_train, amazon_test = ttsplit(amazon_data, 0.2)\n",
        "imdb_train, imdb_test = ttsplit(imdb_data, 0.2)\n",
        "yelp_train, yelp_test = ttsplit(yelp_data, 0.2)"
      ],
      "metadata": {
        "id": "L1sUk1aHS2EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_frame_simple_txt2vec_2(df,min_length=4,max_cut=32,w_dict=None,cutoff=0.7):\n",
        "    txt_lst=[]\n",
        "    max_len=0\n",
        "    for txt in df.text:\n",
        "        txtsplit=txt.lower().replace(\".\",\"\").replace(\",\",\"\").replace(\"?\",\" ?\").replace(\"!\",\" !\").replace(\"&\",\" and \").replace(\"(\",\" ( \").replace(\")\",\" ) \").split()\n",
        "        txt_lst=txt_lst+txtsplit\n",
        "        if max_len< len(txtsplit):\n",
        "            max_len=len(txtsplit)\n",
        "    w_set=set(txt_lst)\n",
        "\n",
        "    comm_lst=Counter(txt_lst).most_common()\n",
        "\n",
        "    if w_dict==None:\n",
        "        w_dict={}\n",
        "        ind=int(len(comm_lst)*cutoff)\n",
        "        for elem in comm_lst:\n",
        "            w_dict[elem[0]]=ind\n",
        "            ind-=1\n",
        "            if ind == 0:\n",
        "                break\n",
        "    #w_dict={}\n",
        "    #ind=1\n",
        "    #for elem in w_set:\n",
        "    #    w_dict[elem]=ind\n",
        "    #    ind+=1\n",
        "\n",
        "    if max_len%2 !=0:\n",
        "        max_len+=1\n",
        "    if max_len<min_length:\n",
        "        max_len=min_length\n",
        "\n",
        "    label_list=[]\n",
        "    Txt_list=[]\n",
        "    for i, txt in enumerate(df.text):\n",
        "        w_list=[]\n",
        "        for word in df.text[i].split():\n",
        "            if word in w_dict:\n",
        "                w_list.append(w_dict[word])\n",
        "            else:\n",
        "                w_list.append(len(w_dict.keys())+1)\n",
        "        if len(w_list) < max_cut:\n",
        "            w_list=w_list+(max_cut-len(w_list))*[0]\n",
        "        else:\n",
        "            w_list=w_list[:max_cut]\n",
        "        #print(torch.tensor(w_list))\n",
        "        label_list.append(torch.tensor(df.label[i]))\n",
        "        Txt_list.append(torch.tensor(w_list))\n",
        "    label_tensor=torch.tensor(label_list)\n",
        "    txt_tensor=torch.stack(Txt_list)\n",
        "\n",
        "    return data_utils.TensorDataset(txt_tensor,label_tensor),w_dict"
      ],
      "metadata": {
        "id": "NmtPc1VwS72O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train, data_test=amazon_train, amazon_test\n",
        "tdf_train,train_dict=data_frame_simple_txt2vec_2(data_train,max_cut=32)\n",
        "tdf_test,_=data_frame_simple_txt2vec_2(data_test,max_cut=32,w_dict=train_dict)"
      ],
      "metadata": {
        "id": "95QPotyBTAsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(tdf_train, shuffle=True, batch_size=200)\n",
        "testloader = DataLoader(tdf_test, shuffle=True, batch_size=200)"
      ],
      "metadata": {
        "id": "5HExPQ56TOB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#embed_dim: int,num_head: int, ff_dim: int,\n",
        "model=TextClassifier(12,6,1,2,2400,ffn_dim=8).to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS2AghHETQZh",
        "outputId": "ee42ed62-56ac-4b07-a67a-0e34200596b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++ There will be 1 transformer blocks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOSu_Kx0TbSS",
        "outputId": "79f9af92-d024-454c-dc09-b984a721b6fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS=300\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "train_loss_history=[]\n",
        "train_accuracy_history=[]\n",
        "criterion = torch.nn.BCELoss()\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = []\n",
        "    acc=0\n",
        "    total_len=0\n",
        "    for batch in tqdm(trainloader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float())\n",
        "\n",
        "        train_loss.append(loss.detach().cpu().item()) # len(images)\n",
        "        total_len += len(images)\n",
        "\n",
        "        acc+=binary_accuracy(outputs, labels)*len(images)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    accuracy =  acc / total_len\n",
        "    train_loss_history.append(np.mean(train_loss))\n",
        "    train_accuracy_history.append(accuracy)\n",
        "    print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {np.mean(train_loss):.2f} accuracy:{accuracy}\")\n",
        "    total_len=0\n",
        "    acc1=0\n",
        "    for batch in tqdm(testloader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float())\n",
        "\n",
        "        train_loss.append(loss.detach().cpu().item()) # len(images)\n",
        "        total_len += len(images)\n",
        "\n",
        "        acc1+=binary_accuracy(outputs, labels)*len(images)\n",
        "    acc1 =  acc1 / total_len\n",
        "\n",
        "    print('Testing Accuracy:', acc1)\n",
        "    #Test_acc.append(acc1)"
      ],
      "metadata": {
        "id": "LQYXfUDsUZFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train, data_test=imdb_train, imdb_test\n",
        "tdf_train,train_dict=data_frame_simple_txt2vec_2(data_train,max_cut=71)\n",
        "tdf_test,_=data_frame_simple_txt2vec_2(data_test,max_cut=71,w_dict=train_dict)"
      ],
      "metadata": {
        "id": "Y5jDeLYbUmP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(tdf_train, shuffle=True, batch_size=200)\n",
        "testloader = DataLoader(tdf_test, shuffle=True, batch_size=200)"
      ],
      "metadata": {
        "id": "KnboKGFZVb7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#embed_dim: int,num_head: int, ff_dim: int,\n",
        "model=TextClassifier(12,6,1,2,3300,ffn_dim=8).to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLsXg_lxVnKF",
        "outputId": "e3b073d5-98da-4161-ae22-47af58962655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++ There will be 1 transformer blocks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2P41VxgjVtgZ",
        "outputId": "5c6b297e-2b31-4801-c0dd-05a552a9de02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS=300\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "train_loss_history=[]\n",
        "train_accuracy_history=[]\n",
        "criterion = torch.nn.BCELoss()\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = []\n",
        "    acc=0\n",
        "    total_len=0\n",
        "    for batch in tqdm(trainloader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float())\n",
        "\n",
        "        train_loss.append(loss.detach().cpu().item()) # len(images)\n",
        "        total_len += len(images)\n",
        "\n",
        "        acc+=binary_accuracy(outputs, labels)*len(images)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    accuracy =  acc / total_len\n",
        "    train_loss_history.append(np.mean(train_loss))\n",
        "    train_accuracy_history.append(accuracy)\n",
        "    print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {np.mean(train_loss):.2f} accuracy:{accuracy}\")\n",
        "    total_len=0\n",
        "    acc1=0\n",
        "    for batch in tqdm(testloader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float())\n",
        "\n",
        "        train_loss.append(loss.detach().cpu().item()) # len(images)\n",
        "        total_len += len(images)\n",
        "\n",
        "        acc1+=binary_accuracy(outputs, labels)*len(images)\n",
        "    acc1 =  acc1 / total_len\n",
        "\n",
        "    print('Testing Accuracy:', acc1)"
      ],
      "metadata": {
        "id": "ill0rOlAWDC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train, data_test=yelp_train, yelp_test\n",
        "tdf_train,train_dict=data_frame_simple_txt2vec_2(data_train,max_cut=32)\n",
        "tdf_test,_=data_frame_simple_txt2vec_2(data_test,max_cut=32,w_dict=train_dict)"
      ],
      "metadata": {
        "id": "WkzbCvlfXZwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(tdf_train, shuffle=True, batch_size=200)\n",
        "testloader = DataLoader(tdf_test, shuffle=True, batch_size=200)"
      ],
      "metadata": {
        "id": "BYnb8kkHXhio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#embed_dim: int,num_head: int, ff_dim: int,\n",
        "model=TextClassifier(12,6,1,2,2000,ffn_dim=8).to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHePkrzsXoWX",
        "outputId": "ff57c7c6-b2f8-4871-f574-2d572840895a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++ There will be 1 transformer blocks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXCm3oK9Xr1T",
        "outputId": "bf80e5c2-5a6e-4359-9c6d-016da2e9aeef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS=300\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "train_loss_history=[]\n",
        "train_accuracy_history=[]\n",
        "criterion = torch.nn.BCELoss()\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = []\n",
        "    acc=0\n",
        "    total_len=0\n",
        "    for batch in tqdm(trainloader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float())\n",
        "\n",
        "        train_loss.append(loss.detach().cpu().item()) # len(images)\n",
        "        total_len += len(images)\n",
        "\n",
        "        acc+=binary_accuracy(outputs, labels)*len(images)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    accuracy =  acc / total_len\n",
        "    train_loss_history.append(np.mean(train_loss))\n",
        "    train_accuracy_history.append(accuracy)\n",
        "    print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {np.mean(train_loss):.2f} accuracy:{accuracy}\")\n",
        "    total_len=0\n",
        "    acc1=0\n",
        "    for batch in tqdm(testloader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float())\n",
        "\n",
        "        train_loss.append(loss.detach().cpu().item()) # len(images)\n",
        "        total_len += len(images)\n",
        "\n",
        "        acc1+=binary_accuracy(outputs, labels)*len(images)\n",
        "    acc1 =  acc1 / total_len\n",
        "\n",
        "    print('Testing Accuracy:', acc1)"
      ],
      "metadata": {
        "id": "IBrVVRzNXvb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JFnMxL-XXyYs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
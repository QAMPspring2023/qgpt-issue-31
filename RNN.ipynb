{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gja09oxE62Zn"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow_datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/CQCL/qnlp_lorenz_etal_2021_resources\n",
        "!mv qnlp_lorenz_etal_2021_resources/datasets mc_rp_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41IDaAK_63Yt",
        "outputId": "46f82f23-0ab7-4c74-f5d8-23fd71644137"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'qnlp_lorenz_etal_2021_resources' already exists and is not an empty directory.\n",
            "mv: cannot stat 'qnlp_lorenz_etal_2021_resources/datasets': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from joblib import load, dump\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "f1ipLQzF7oAZ"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc_rp_sets_path = Path(\"mc_rp_dataset\")\n",
        "mc_rp_sets = list(mc_rp_sets_path.glob(\"*.txt\"))\n",
        "mc_datasets, rp_datasets = list(filter(lambda x: x.name.startswith(\"mc\"), mc_rp_sets)), list(filter(lambda x: x.name.startswith(\"rp\"), mc_rp_sets))"
      ],
      "metadata": {
        "id": "3j0gUc9-7Xh2"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "iXfyn_Q387bl"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_process_mcrp(datapaths: dict):\n",
        "  def rm(text):\n",
        "    return \" \".join(list(map(lambda x: x[:x.find('_')], text.split())))\n",
        "  retval = {}\n",
        "  for datapath in datapaths:\n",
        "    if \"rp\" in str(datapath):\n",
        "      sel = 2\n",
        "    else:\n",
        "      sel = 3\n",
        "    df = pd.DataFrame(list(map(lambda x: [int(x[0]), x[sel:]], datapath.read_text().split(\"\\n\"))), columns=['label', 'text'])\n",
        "    df['text'] = df['text'].apply(rm)\n",
        "    retval[datapath.name.split(\".\")[0]] = df\n",
        "  return retval\n",
        "\n",
        "mc_data, rp_data = read_process_mcrp(mc_datasets), read_process_mcrp(rp_datasets)"
      ],
      "metadata": {
        "id": "mvGIbXfhBW73"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rp_data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t07fe9rqQvSL",
        "outputId": "ce865c51-1f8a-4e27-a5ea-5b86a20d0d6a"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['rp_test_data', 'rp_train_data'])"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MC Task"
      ],
      "metadata": {
        "id": "54G6uqtrQiW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mc_data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acNiKSL3JXJy",
        "outputId": "5858dc3f-c867-41e3-8b50-cd3de98fc3a2"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['mc_dev_data', 'mc_train_data', 'mc_test_data'])"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds=tf.data.Dataset.from_tensor_slices((\n",
        "            tf.cast(mc_data['mc_train_data'].text.values, tf.string),\n",
        "            tf.cast(mc_data['mc_train_data'].label.values, tf.int64)\n",
        "        ))"
      ],
      "metadata": {
        "id": "bP8uxSV3HrCD"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_data=tf.data.Dataset.from_tensor_slices((\n",
        "            tf.cast(mc_data['mc_test_data'].text.values, tf.string),\n",
        "            tf.cast(mc_data['mc_test_data'].label.values, tf.int64)\n",
        "        ))"
      ],
      "metadata": {
        "id": "A-zjzzEYOv8P"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 100\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "\n",
        "ds = ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "v_data = v_data.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "YJ97rU2jNOhq"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example, label in ds.take(1):\n",
        "    print(f\"Texts : {example.numpy()[:3]} \\n\")\n",
        "    print(f\"Labels: {label.numpy()[:3]} \\n\")\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azch-v34DnZ9",
        "outputId": "aa402d6f-0d6e-4e6d-b002-32ab9e284b66"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texts : [b'woman runs useful application' b'man cooks tasty meal'\n",
            " b'person cooks meal'] \n",
            "\n",
            "Labels: [0 1 1] \n",
            "\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 20\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(ds.map(lambda text, label: text))\n",
        "\n",
        "vocab = np.array(encoder.get_vocabulary())"
      ],
      "metadata": {
        "id": "F0Ysw5iU7ppe"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example.numpy()[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzHP5i8zMhE5",
        "outputId": "b7fa19dd-7b90-4186-b37f-475985512b6d"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'woman runs useful application', b'man cooks tasty meal',\n",
              "       b'person cooks meal'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_example = encoder(example)[:].numpy()\n",
        "encoded_example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O-pB2MSLvHJ",
        "outputId": "cd44ff23-c6e4-43da-8854-1ff46e3e6852"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4, 11, 13, 18],\n",
              "       [ 2,  8, 10,  7],\n",
              "       [ 3,  8,  7,  0],\n",
              "       [ 2,  6, 13, 18],\n",
              "       [ 2, 11, 14,  0],\n",
              "       [ 5,  2, 11, 14],\n",
              "       [ 5,  3,  9,  7],\n",
              "       [ 3,  6, 14,  0],\n",
              "       [ 4,  9, 12,  0],\n",
              "       [ 4,  8, 10, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_example = encoder(example)[:3].numpy()\n",
        "encoded_example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFMIipzhIqn3",
        "outputId": "03ca2b55-7b21-43ea-e659-f718a9859073"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4, 11, 13, 18],\n",
              "       [ 2,  8, 10,  7],\n",
              "       [ 3,  8,  7,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=2,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "8D6elvHKIuhV"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34NSt17_P0sl",
        "outputId": "89d2b28e-12ee-4391-f339-6b153a41326d"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_6 (Text  (None, None)              0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_9 (Embedding)     (None, None, 2)           38        \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirecti  (None, 16)                704       \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 887 (3.46 KB)\n",
            "Trainable params: 887 (3.46 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BpQPJpcwIx_3"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(ds, epochs=180,\n",
        "                    validation_data=v_data,\n",
        "                    validation_steps=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AttgV3m2JDJc",
        "outputId": "719b6b4b-5b7a-4885-b8c9-0cef4f33ae05"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/180\n",
            "1/7 [===>..........................] - ETA: 55s - loss: 0.6919 - accuracy: 0.4000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 13s 647ms/step - loss: 0.6921 - accuracy: 0.4429 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
            "Epoch 2/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6898 - accuracy: 0.4429\n",
            "Epoch 3/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6877 - accuracy: 0.4429\n",
            "Epoch 4/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6849 - accuracy: 0.4429\n",
            "Epoch 5/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6820 - accuracy: 0.4429\n",
            "Epoch 6/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6773 - accuracy: 0.4429\n",
            "Epoch 7/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.6717 - accuracy: 0.4429\n",
            "Epoch 8/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6641 - accuracy: 0.4429\n",
            "Epoch 9/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6547 - accuracy: 0.4429\n",
            "Epoch 10/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.6416 - accuracy: 0.4429\n",
            "Epoch 11/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6249 - accuracy: 0.4429\n",
            "Epoch 12/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.6040 - accuracy: 0.5143\n",
            "Epoch 13/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.5807 - accuracy: 0.7143\n",
            "Epoch 14/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.5509 - accuracy: 0.9143\n",
            "Epoch 15/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5191 - accuracy: 0.9857\n",
            "Epoch 16/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.4841 - accuracy: 0.9857\n",
            "Epoch 17/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.4457 - accuracy: 1.0000\n",
            "Epoch 18/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.4059 - accuracy: 1.0000\n",
            "Epoch 19/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.3687 - accuracy: 1.0000\n",
            "Epoch 20/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.3325 - accuracy: 1.0000\n",
            "Epoch 21/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2985 - accuracy: 1.0000\n",
            "Epoch 22/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2681 - accuracy: 1.0000\n",
            "Epoch 23/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.2390 - accuracy: 1.0000\n",
            "Epoch 24/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.2120 - accuracy: 1.0000\n",
            "Epoch 25/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1877 - accuracy: 1.0000\n",
            "Epoch 26/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.1642 - accuracy: 1.0000\n",
            "Epoch 27/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.1412 - accuracy: 1.0000\n",
            "Epoch 28/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1227 - accuracy: 1.0000\n",
            "Epoch 29/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.1041 - accuracy: 1.0000\n",
            "Epoch 30/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 1.0000\n",
            "Epoch 31/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0729 - accuracy: 1.0000\n",
            "Epoch 32/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0617 - accuracy: 1.0000\n",
            "Epoch 33/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0510 - accuracy: 1.0000\n",
            "Epoch 34/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 1.0000\n",
            "Epoch 35/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0361 - accuracy: 1.0000\n",
            "Epoch 36/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 1.0000\n",
            "Epoch 37/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 38/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 1.0000\n",
            "Epoch 39/180\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 40/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0175 - accuracy: 1.0000\n",
            "Epoch 41/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0157 - accuracy: 1.0000\n",
            "Epoch 42/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 43/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 44/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 45/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0104 - accuracy: 1.0000\n",
            "Epoch 46/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 47/180\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 48/180\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 49/180\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 50/180\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 51/180\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 52/180\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 53/180\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 54/180\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 55/180\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 56/180\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 57/180\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 58/180\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 59/180\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 60/180\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 61/180\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 62/180\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 63/180\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 64/180\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 65/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 66/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 67/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 68/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 69/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 70/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 71/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 72/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 73/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 74/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 75/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 76/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 77/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 78/180\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 79/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 80/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 81/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 82/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 83/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 84/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 85/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 86/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 87/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 88/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 89/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 90/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 91/180\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 92/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 93/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 94/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 95/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 96/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 97/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 98/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 9.8391e-04 - accuracy: 1.0000\n",
            "Epoch 99/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 9.5704e-04 - accuracy: 1.0000\n",
            "Epoch 100/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 9.3560e-04 - accuracy: 1.0000\n",
            "Epoch 101/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 9.1432e-04 - accuracy: 1.0000\n",
            "Epoch 102/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 8.9121e-04 - accuracy: 1.0000\n",
            "Epoch 103/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 8.7116e-04 - accuracy: 1.0000\n",
            "Epoch 104/180\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 8.5116e-04 - accuracy: 1.0000\n",
            "Epoch 105/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 8.2991e-04 - accuracy: 1.0000\n",
            "Epoch 106/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 8.1327e-04 - accuracy: 1.0000\n",
            "Epoch 107/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 7.9600e-04 - accuracy: 1.0000\n",
            "Epoch 108/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 7.7788e-04 - accuracy: 1.0000\n",
            "Epoch 109/180\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 7.5953e-04 - accuracy: 1.0000\n",
            "Epoch 110/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 7.4453e-04 - accuracy: 1.0000\n",
            "Epoch 111/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 7.2835e-04 - accuracy: 1.0000\n",
            "Epoch 112/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 7.1201e-04 - accuracy: 1.0000\n",
            "Epoch 113/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 6.9685e-04 - accuracy: 1.0000\n",
            "Epoch 114/180\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 6.8477e-04 - accuracy: 1.0000\n",
            "Epoch 115/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 6.6968e-04 - accuracy: 1.0000\n",
            "Epoch 116/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 6.5607e-04 - accuracy: 1.0000\n",
            "Epoch 117/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 6.4362e-04 - accuracy: 1.0000\n",
            "Epoch 118/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 6.3044e-04 - accuracy: 1.0000\n",
            "Epoch 119/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 6.1785e-04 - accuracy: 1.0000\n",
            "Epoch 120/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 6.0508e-04 - accuracy: 1.0000\n",
            "Epoch 121/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.9550e-04 - accuracy: 1.0000\n",
            "Epoch 122/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.8284e-04 - accuracy: 1.0000\n",
            "Epoch 123/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 5.7278e-04 - accuracy: 1.0000\n",
            "Epoch 124/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.6123e-04 - accuracy: 1.0000\n",
            "Epoch 125/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 5.5033e-04 - accuracy: 1.0000\n",
            "Epoch 126/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.4174e-04 - accuracy: 1.0000\n",
            "Epoch 127/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.3076e-04 - accuracy: 1.0000\n",
            "Epoch 128/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.2219e-04 - accuracy: 1.0000\n",
            "Epoch 129/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.1204e-04 - accuracy: 1.0000\n",
            "Epoch 130/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 5.0402e-04 - accuracy: 1.0000\n",
            "Epoch 131/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 4.9379e-04 - accuracy: 1.0000\n",
            "Epoch 132/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 4.8595e-04 - accuracy: 1.0000\n",
            "Epoch 133/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 4.7665e-04 - accuracy: 1.0000\n",
            "Epoch 134/180\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4.7020e-04 - accuracy: 1.0000\n",
            "Epoch 135/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 4.6084e-04 - accuracy: 1.0000\n",
            "Epoch 136/180\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 4.5363e-04 - accuracy: 1.0000\n",
            "Epoch 137/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 4.4624e-04 - accuracy: 1.0000\n",
            "Epoch 138/180\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4.3815e-04 - accuracy: 1.0000\n",
            "Epoch 139/180\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 4.3154e-04 - accuracy: 1.0000\n",
            "Epoch 140/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 4.2467e-04 - accuracy: 1.0000\n",
            "Epoch 141/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 4.1788e-04 - accuracy: 1.0000\n",
            "Epoch 142/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 4.1096e-04 - accuracy: 1.0000\n",
            "Epoch 143/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 4.0436e-04 - accuracy: 1.0000\n",
            "Epoch 144/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.9762e-04 - accuracy: 1.0000\n",
            "Epoch 145/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 3.9148e-04 - accuracy: 1.0000\n",
            "Epoch 146/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 3.8530e-04 - accuracy: 1.0000\n",
            "Epoch 147/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.7957e-04 - accuracy: 1.0000\n",
            "Epoch 148/180\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 3.7367e-04 - accuracy: 1.0000\n",
            "Epoch 149/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.6876e-04 - accuracy: 1.0000\n",
            "Epoch 150/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 3.6283e-04 - accuracy: 1.0000\n",
            "Epoch 151/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.5724e-04 - accuracy: 1.0000\n",
            "Epoch 152/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.5170e-04 - accuracy: 1.0000\n",
            "Epoch 153/180\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 3.4652e-04 - accuracy: 1.0000\n",
            "Epoch 154/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.4139e-04 - accuracy: 1.0000\n",
            "Epoch 155/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 3.3688e-04 - accuracy: 1.0000\n",
            "Epoch 156/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.3197e-04 - accuracy: 1.0000\n",
            "Epoch 157/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.2662e-04 - accuracy: 1.0000\n",
            "Epoch 158/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.2242e-04 - accuracy: 1.0000\n",
            "Epoch 159/180\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 3.1786e-04 - accuracy: 1.0000\n",
            "Epoch 160/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 3.1319e-04 - accuracy: 1.0000\n",
            "Epoch 161/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 3.0909e-04 - accuracy: 1.0000\n",
            "Epoch 162/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 3.0450e-04 - accuracy: 1.0000\n",
            "Epoch 163/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 3.0068e-04 - accuracy: 1.0000\n",
            "Epoch 164/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.9627e-04 - accuracy: 1.0000\n",
            "Epoch 165/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.9216e-04 - accuracy: 1.0000\n",
            "Epoch 166/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.8787e-04 - accuracy: 1.0000\n",
            "Epoch 167/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.8436e-04 - accuracy: 1.0000\n",
            "Epoch 168/180\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 2.8077e-04 - accuracy: 1.0000\n",
            "Epoch 169/180\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 2.7696e-04 - accuracy: 1.0000\n",
            "Epoch 170/180\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 2.7312e-04 - accuracy: 1.0000\n",
            "Epoch 171/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.6974e-04 - accuracy: 1.0000\n",
            "Epoch 172/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.6614e-04 - accuracy: 1.0000\n",
            "Epoch 173/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.6252e-04 - accuracy: 1.0000\n",
            "Epoch 174/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.5940e-04 - accuracy: 1.0000\n",
            "Epoch 175/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.5595e-04 - accuracy: 1.0000\n",
            "Epoch 176/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.5243e-04 - accuracy: 1.0000\n",
            "Epoch 177/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.4948e-04 - accuracy: 1.0000\n",
            "Epoch 178/180\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 2.4629e-04 - accuracy: 1.0000\n",
            "Epoch 179/180\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 2.4323e-04 - accuracy: 1.0000\n",
            "Epoch 180/180\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 2.4012e-04 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RP Task"
      ],
      "metadata": {
        "id": "c_mGN54RQmua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds=tf.data.Dataset.from_tensor_slices((\n",
        "            tf.cast(rp_data['rp_train_data'].text.values, tf.string),\n",
        "            tf.cast(rp_data['rp_train_data'].label.values, tf.int64)\n",
        "        ))"
      ],
      "metadata": {
        "id": "ZFhumK3sQmfR"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_data=tf.data.Dataset.from_tensor_slices((\n",
        "            tf.cast(rp_data['rp_test_data'].text.values, tf.string),\n",
        "            tf.cast(rp_data['rp_test_data'].label.values, tf.int64)\n",
        "        ))"
      ],
      "metadata": {
        "id": "WoR7pxlFK2Hp"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 100\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "\n",
        "ds = ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "v_data = v_data.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "9FaGLQZfREpk"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example, label in ds.take(1):\n",
        "    print(f\"Texts : {example.numpy()[:3]} \\n\")\n",
        "    print(f\"Labels: {label.numpy()[:3]} \\n\")\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICdCvQyTRIHJ",
        "outputId": "3eb8173e-643b-416b-fcda-a35cfa148c62"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texts : [b'person that join movement' b'quality that church teach'\n",
            " b'player that strike batter'] \n",
            "\n",
            "Labels: [0 1 0] \n",
            "\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 100\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(ds.map(lambda text, label: text))\n",
        "\n",
        "vocab = np.array(encoder.get_vocabulary())"
      ],
      "metadata": {
        "id": "N68LtlWHRj2-"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_example = encoder(example)[:].numpy()\n",
        "encoded_example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy4aR7EMRLXS",
        "outputId": "c2f87257-b5e3-4bb6-895a-8e30f2294a33"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9,  2, 14, 37],\n",
              "       [24,  2, 12, 63],\n",
              "       [ 8,  2, 21, 54],\n",
              "       [ 8,  2, 96, 72],\n",
              "       [ 3,  2, 71, 14],\n",
              "       [10,  2, 30, 21],\n",
              "       [ 6,  2, 68, 48],\n",
              "       [ 4,  2, 15, 11],\n",
              "       [56,  2, 53, 23],\n",
              "       [ 3,  2, 47, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=2,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "VvLBjBaGRPVA"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rvDWcTORvmo",
        "outputId": "6813f72c-2786-485a-a611-af5b5c84f0b7"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_7 (Text  (None, None)              0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_10 (Embedding)    (None, None, 2)           196       \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirect  (None, 16)                704       \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1045 (4.08 KB)\n",
            "Trainable params: 1045 (4.08 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "D68kIglPR1Nt"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(ds, epochs=300,\n",
        "                    validation_data=v_data,\n",
        "                    validation_steps=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgldd_XJR6xt",
        "outputId": "3ea15ea0-e9e5-4660-99da-9322931e0dc8"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.6910 - accuracy: 0.3714  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8/8 [==============================] - 13s 416ms/step - loss: 0.6912 - accuracy: 0.3784 - val_loss: 0.6886 - val_accuracy: 0.3871\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6869 - accuracy: 0.3784\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6830 - accuracy: 0.3784\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6809 - accuracy: 0.3784\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6771 - accuracy: 0.3784\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6741 - accuracy: 0.3784\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6703 - accuracy: 0.3784\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6666 - accuracy: 0.3784\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6632 - accuracy: 0.3784\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6595 - accuracy: 0.3784\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6560 - accuracy: 0.3784\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6511 - accuracy: 0.3784\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6467 - accuracy: 0.4324\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6407 - accuracy: 0.5541\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6359 - accuracy: 0.7568\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6285 - accuracy: 0.8378\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.6215 - accuracy: 0.8378\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.6128 - accuracy: 0.8378\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.6031 - accuracy: 0.8784\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.5901 - accuracy: 0.9189\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.5758 - accuracy: 0.9189\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5597 - accuracy: 0.9189\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5407 - accuracy: 0.9189\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5218 - accuracy: 0.9189\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.5002 - accuracy: 0.9189\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.4806 - accuracy: 0.9054\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4593 - accuracy: 0.9189\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4388 - accuracy: 0.9324\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.4206 - accuracy: 0.9324\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.4051 - accuracy: 0.9324\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.3915 - accuracy: 0.9324\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.3761 - accuracy: 0.9324\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3621 - accuracy: 0.9324\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.9459\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3377 - accuracy: 0.9459\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3245 - accuracy: 0.9459\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3129 - accuracy: 0.9595\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3023 - accuracy: 0.9595\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2897 - accuracy: 0.9459\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2775 - accuracy: 0.9459\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2657 - accuracy: 0.9459\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2531 - accuracy: 0.9459\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2415 - accuracy: 0.9595\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2251 - accuracy: 0.9730\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2126 - accuracy: 0.9595\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1981 - accuracy: 0.9865\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1841 - accuracy: 0.9865\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1683 - accuracy: 0.9865\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1542 - accuracy: 0.9865\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1443 - accuracy: 0.9865\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1300 - accuracy: 0.9865\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1179 - accuracy: 0.9865\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1078 - accuracy: 0.9865\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0987 - accuracy: 0.9865\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0903 - accuracy: 0.9865\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0841 - accuracy: 0.9865\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0779 - accuracy: 0.9865\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0730 - accuracy: 0.9865\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0694 - accuracy: 0.9865\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0666 - accuracy: 0.9865\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0642 - accuracy: 0.9865\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0622 - accuracy: 0.9865\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0601 - accuracy: 0.9865\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0592 - accuracy: 0.9865\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0575 - accuracy: 0.9865\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0564 - accuracy: 0.9865\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0555 - accuracy: 0.9865\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0550 - accuracy: 0.9865\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0544 - accuracy: 0.9865\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0541 - accuracy: 0.9865\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0533 - accuracy: 0.9865\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0525 - accuracy: 0.9865\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0526 - accuracy: 0.9865\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0518 - accuracy: 0.9865\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0504 - accuracy: 0.9865\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0505 - accuracy: 0.9865\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0493 - accuracy: 0.9865\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0486 - accuracy: 0.9865\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0482 - accuracy: 0.9865\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0479 - accuracy: 0.9865\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0469 - accuracy: 0.9865\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0463 - accuracy: 0.9865\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0463 - accuracy: 0.9865\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0456 - accuracy: 0.9865\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0449 - accuracy: 0.9865\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0437 - accuracy: 0.9865\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0431 - accuracy: 0.9865\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 0.9865\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9865\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 0.9865\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0393 - accuracy: 0.9865\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0404 - accuracy: 0.9865\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0401 - accuracy: 0.9865\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 0.9865\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9865\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0313 - accuracy: 0.9730\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 0.9865\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0260 - accuracy: 0.9865\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 0.9865\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0277 - accuracy: 0.9730\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0164 - accuracy: 1.0000\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0134 - accuracy: 1.0000\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 9.7486e-04 - accuracy: 1.0000\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 9.4374e-04 - accuracy: 1.0000\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9.0492e-04 - accuracy: 1.0000\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 8.6205e-04 - accuracy: 1.0000\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 8.4897e-04 - accuracy: 1.0000\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 8.1391e-04 - accuracy: 1.0000\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 7.8581e-04 - accuracy: 1.0000\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 7.5373e-04 - accuracy: 1.0000\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 7.3117e-04 - accuracy: 1.0000\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 7.2691e-04 - accuracy: 1.0000\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.9204e-04 - accuracy: 1.0000\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6.7689e-04 - accuracy: 1.0000\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 6.3574e-04 - accuracy: 1.0000\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 6.2151e-04 - accuracy: 1.0000\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 6.0601e-04 - accuracy: 1.0000\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.8235e-04 - accuracy: 1.0000\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.6936e-04 - accuracy: 1.0000\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.5354e-04 - accuracy: 1.0000\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.3613e-04 - accuracy: 1.0000\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5.2531e-04 - accuracy: 1.0000\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 5.0876e-04 - accuracy: 1.0000\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.9687e-04 - accuracy: 1.0000\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 4.8605e-04 - accuracy: 1.0000\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.7490e-04 - accuracy: 1.0000\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.6662e-04 - accuracy: 1.0000\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.5182e-04 - accuracy: 1.0000\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.4499e-04 - accuracy: 1.0000\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.2952e-04 - accuracy: 1.0000\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.2106e-04 - accuracy: 1.0000\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 4.1027e-04 - accuracy: 1.0000\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 4.0040e-04 - accuracy: 1.0000\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.9084e-04 - accuracy: 1.0000\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.8451e-04 - accuracy: 1.0000\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3.7623e-04 - accuracy: 1.0000\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.6835e-04 - accuracy: 1.0000\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.6057e-04 - accuracy: 1.0000\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.5333e-04 - accuracy: 1.0000\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.4664e-04 - accuracy: 1.0000\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3.4021e-04 - accuracy: 1.0000\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.3342e-04 - accuracy: 1.0000\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.2867e-04 - accuracy: 1.0000\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.2188e-04 - accuracy: 1.0000\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.1528e-04 - accuracy: 1.0000\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.0944e-04 - accuracy: 1.0000\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3.0448e-04 - accuracy: 1.0000\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.9776e-04 - accuracy: 1.0000\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.9394e-04 - accuracy: 1.0000\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.9021e-04 - accuracy: 1.0000\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.8346e-04 - accuracy: 1.0000\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 2.7763e-04 - accuracy: 1.0000\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.7320e-04 - accuracy: 1.0000\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.6863e-04 - accuracy: 1.0000\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.6313e-04 - accuracy: 1.0000\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.5902e-04 - accuracy: 1.0000\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.5501e-04 - accuracy: 1.0000\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.5055e-04 - accuracy: 1.0000\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.4616e-04 - accuracy: 1.0000\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.4167e-04 - accuracy: 1.0000\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.3765e-04 - accuracy: 1.0000\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.3501e-04 - accuracy: 1.0000\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.3026e-04 - accuracy: 1.0000\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.2623e-04 - accuracy: 1.0000\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 2.2179e-04 - accuracy: 1.0000\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.1916e-04 - accuracy: 1.0000\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.1507e-04 - accuracy: 1.0000\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.1164e-04 - accuracy: 1.0000\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2.0830e-04 - accuracy: 1.0000\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.0638e-04 - accuracy: 1.0000\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 2.0190e-04 - accuracy: 1.0000\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9999e-04 - accuracy: 1.0000\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9660e-04 - accuracy: 1.0000\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9409e-04 - accuracy: 1.0000\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.9046e-04 - accuracy: 1.0000\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.8827e-04 - accuracy: 1.0000\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.8494e-04 - accuracy: 1.0000\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.8252e-04 - accuracy: 1.0000\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.7924e-04 - accuracy: 1.0000\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7644e-04 - accuracy: 1.0000\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7315e-04 - accuracy: 1.0000\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.7186e-04 - accuracy: 1.0000\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.6752e-04 - accuracy: 1.0000\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.6624e-04 - accuracy: 1.0000\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.6323e-04 - accuracy: 1.0000\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.6120e-04 - accuracy: 1.0000\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.5838e-04 - accuracy: 1.0000\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.5735e-04 - accuracy: 1.0000\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.5484e-04 - accuracy: 1.0000\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.5254e-04 - accuracy: 1.0000\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.5160e-04 - accuracy: 1.0000\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.4874e-04 - accuracy: 1.0000\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4636e-04 - accuracy: 1.0000\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 1.4530e-04 - accuracy: 1.0000\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.4326e-04 - accuracy: 1.0000\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 1.4130e-04 - accuracy: 1.0000\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.3986e-04 - accuracy: 1.0000\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.3784e-04 - accuracy: 1.0000\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 1.3552e-04 - accuracy: 1.0000\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.3391e-04 - accuracy: 1.0000\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.3284e-04 - accuracy: 1.0000\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.2986e-04 - accuracy: 1.0000\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.2881e-04 - accuracy: 1.0000\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.2677e-04 - accuracy: 1.0000\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.2528e-04 - accuracy: 1.0000\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 1.2404e-04 - accuracy: 1.0000\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.2270e-04 - accuracy: 1.0000\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.2108e-04 - accuracy: 1.0000\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.2009e-04 - accuracy: 1.0000\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 1.1847e-04 - accuracy: 1.0000\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.1667e-04 - accuracy: 1.0000\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 1.1560e-04 - accuracy: 1.0000\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 1.1449e-04 - accuracy: 1.0000\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.1294e-04 - accuracy: 1.0000\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.1187e-04 - accuracy: 1.0000\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.1087e-04 - accuracy: 1.0000\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.0944e-04 - accuracy: 1.0000\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.0797e-04 - accuracy: 1.0000\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0751e-04 - accuracy: 1.0000\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 1.0578e-04 - accuracy: 1.0000\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.0460e-04 - accuracy: 1.0000\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.0345e-04 - accuracy: 1.0000\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0229e-04 - accuracy: 1.0000\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0126e-04 - accuracy: 1.0000\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 1.0031e-04 - accuracy: 1.0000\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 9.8914e-05 - accuracy: 1.0000\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9.7912e-05 - accuracy: 1.0000\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9.6691e-05 - accuracy: 1.0000\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9.5830e-05 - accuracy: 1.0000\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9.4756e-05 - accuracy: 1.0000\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9.3804e-05 - accuracy: 1.0000\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9.2583e-05 - accuracy: 1.0000\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 9.1669e-05 - accuracy: 1.0000\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 9.0708e-05 - accuracy: 1.0000\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 9.0082e-05 - accuracy: 1.0000\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.9198e-05 - accuracy: 1.0000\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.8192e-05 - accuracy: 1.0000\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.7484e-05 - accuracy: 1.0000\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.6660e-05 - accuracy: 1.0000\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.5794e-05 - accuracy: 1.0000\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 8.5049e-05 - accuracy: 1.0000\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 8.4207e-05 - accuracy: 1.0000\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.3518e-05 - accuracy: 1.0000\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.2821e-05 - accuracy: 1.0000\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 8.1598e-05 - accuracy: 1.0000\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8.0765e-05 - accuracy: 1.0000\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.9701e-05 - accuracy: 1.0000\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.9066e-05 - accuracy: 1.0000\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 7.8328e-05 - accuracy: 1.0000\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.7230e-05 - accuracy: 1.0000\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 7.6631e-05 - accuracy: 1.0000\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.6023e-05 - accuracy: 1.0000\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.5158e-05 - accuracy: 1.0000\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.4674e-05 - accuracy: 1.0000\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7.3947e-05 - accuracy: 1.0000\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.3344e-05 - accuracy: 1.0000\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 7.2495e-05 - accuracy: 1.0000\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.1991e-05 - accuracy: 1.0000\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 7.1426e-05 - accuracy: 1.0000\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7.0870e-05 - accuracy: 1.0000\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 7.0120e-05 - accuracy: 1.0000\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.9574e-05 - accuracy: 1.0000\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6.8914e-05 - accuracy: 1.0000\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6.8383e-05 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/static/public/331/sentiment+labelled+sentences.zip\n",
        "!unzip -o sentiment+labelled+sentences.zip\n",
        "!rm \"sentiment labelled sentences/readme.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAgEfbZHSdlg",
        "outputId": "9802e1b3-d4b3-4820-87aa-eca8004f00a2"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-30 20:44:01--  https://archive.ics.uci.edu/static/public/331/sentiment+labelled+sentences.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘sentiment+labelled+sentences.zip’\n",
            "\n",
            "sentiment+labelled+     [  <=>               ]  82.21K   407KB/s    in 0.2s    \n",
            "\n",
            "2023-10-30 20:44:01 (407 KB/s) - ‘sentiment+labelled+sentences.zip’ saved [84188]\n",
            "\n",
            "Archive:  sentiment+labelled+sentences.zip\n",
            "   creating: sentiment labelled sentences/\n",
            "  inflating: sentiment labelled sentences/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/sentiment labelled sentences/\n",
            "  inflating: __MACOSX/sentiment labelled sentences/._.DS_Store  \n",
            "  inflating: sentiment labelled sentences/amazon_cells_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/imdb_labelled.txt  \n",
            "  inflating: __MACOSX/sentiment labelled sentences/._imdb_labelled.txt  \n",
            "  inflating: sentiment labelled sentences/readme.txt  \n",
            "  inflating: __MACOSX/sentiment labelled sentences/._readme.txt  \n",
            "  inflating: sentiment labelled sentences/yelp_labelled.txt  \n",
            "  inflating: __MACOSX/._sentiment labelled sentences  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separating Amazon, IMDb, Yelp dataset paths\n",
        "datasets_path = Path(\"sentiment labelled sentences\")\n",
        "datasets = list(datasets_path.glob(\"*.txt\"))\n",
        "\n",
        "# Reading all data and creating data loaders from our data loading strategy\n",
        "def read_process(datapaths: list):\n",
        "    retval = {}\n",
        "    for datapath in datapaths:\n",
        "        df = pd.DataFrame(list(map(lambda x: x.split(\"\\t\"), datapath.read_text().split(\"\\n\"))), columns=['text', 'label']).dropna()\n",
        "        df['label'] = df['label'].apply(lambda  x: int(x))\n",
        "        retval[datapath.name.split(\".\")[0]] = df\n",
        "    return retval\n",
        "\n",
        "def ttsplit(data: pd.DataFrame, test_size=0.2):\n",
        "    train_data, test_data = train_test_split(data, test_size=test_size, stratify=data['label'], random_state=42)\n",
        "    train_data, test_data = train_data.reset_index().drop(columns=['index']), test_data.reset_index().drop(columns=['index'])\n",
        "    # train_data = pd.DataFrame({'text': X_train, 'labels': y_train})\n",
        "    # test_data = pd.DataFrame({'text': X_test, 'labels': y_test})\n",
        "    return train_data, test_data\n",
        "\n",
        "\n",
        "\n",
        "datadict = read_process(datasets)\n",
        "amazon_data = datadict['amazon_cells_labelled']\n",
        "imdb_data = datadict['imdb_labelled']\n",
        "yelp_data = datadict['yelp_labelled']\n",
        "\n",
        "amazon_train, amazon_test = ttsplit(amazon_data, 0.2)\n",
        "imdb_train, imdb_test = ttsplit(imdb_data, 0.2)\n",
        "yelp_train, yelp_test = ttsplit(yelp_data, 0.2)"
      ],
      "metadata": {
        "id": "wTvNgqubSD-r"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Amazon"
      ],
      "metadata": {
        "id": "x2sYVcvzX9A8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds=tf.data.Dataset.from_tensor_slices((\n",
        "            tf.cast(amazon_train.text.values, tf.string),\n",
        "            tf.cast(amazon_train.label.values, tf.int64)\n",
        "        ))"
      ],
      "metadata": {
        "id": "jDGXORt7VL2V"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_data=tf.data.Dataset.from_tensor_slices((\n",
        "            tf.cast(amazon_test.text.values, tf.string),\n",
        "            tf.cast(amazon_test.label.values, tf.int64)\n",
        "        ))"
      ],
      "metadata": {
        "id": "5WOB6KyyVtp9"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "\n",
        "ds = ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "v_data = v_data.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "mPLvidmoWLDz"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example, label in ds.take(1):\n",
        "    print(f\"Texts : {example.numpy()[:3]} \\n\")\n",
        "    print(f\"Labels: {label.numpy()[:3]} \\n\")\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYsUQblrWRFS",
        "outputId": "c92e16a7-1c31-43b1-d39f-22637a28ed69"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texts : [b'We would recommend these to others.'\n",
            " b'The first thing that happened was that the tracking was off.'\n",
            " b\"But when I check voice mail at night, the keypad backlight turns off a few seconds into the first message, and then I'm lost.\"] \n",
            "\n",
            "Labels: [1 0 0] \n",
            "\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 2400\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(ds.map(lambda text, label: text))\n",
        "\n",
        "vocab = np.array(encoder.get_vocabulary())"
      ],
      "metadata": {
        "id": "2Xtog5NJWXBF"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=2,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "IW7j6dNhWdzA"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81ky-rtAWmFo",
        "outputId": "0f7b5d4b-f545-4542-bb63-0ea180bfa89e"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_9 (Text  (None, None)              0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_11 (Embedding)    (None, None, 2)           3274      \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirect  (None, 16)                704       \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4123 (16.11 KB)\n",
            "Trainable params: 4123 (16.11 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xAcnrINCWqGQ"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(ds, epochs=300,\n",
        "                    validation_data=v_data,\n",
        "                    validation_steps=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4M-5X7ZWwYR",
        "outputId": "ecd71033-0093-47fb-987e-2414dac23a9b"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8/8 [==============================] - 15s 727ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6924 - val_accuracy: 0.5000\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6919 - accuracy: 0.5000\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6899 - accuracy: 0.5000\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6872 - accuracy: 0.5000\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6833 - accuracy: 0.5000\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6779 - accuracy: 0.5000\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6698 - accuracy: 0.5000\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6578 - accuracy: 0.5000\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6417 - accuracy: 0.5000\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6166 - accuracy: 0.5000\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5821 - accuracy: 0.5000\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5338 - accuracy: 0.5163\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4780 - accuracy: 0.6137\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4187 - accuracy: 0.7337\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3646 - accuracy: 0.8000\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3185 - accuracy: 0.8813\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.2731 - accuracy: 0.9150\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.2352 - accuracy: 0.9513\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.2033 - accuracy: 0.9600\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1770 - accuracy: 0.9675\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.1554 - accuracy: 0.9762\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.1385 - accuracy: 0.9737\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.1213 - accuracy: 0.9887\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.1065 - accuracy: 0.9912\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0956 - accuracy: 0.9925\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0863 - accuracy: 0.9925\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0787 - accuracy: 0.9925\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0686 - accuracy: 0.9925\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0602 - accuracy: 0.9925\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0546 - accuracy: 0.9937\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0496 - accuracy: 0.9962\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0455 - accuracy: 0.9937\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0417 - accuracy: 0.9937\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0386 - accuracy: 0.9937\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0356 - accuracy: 0.9937\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0330 - accuracy: 0.9962\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0307 - accuracy: 0.9950\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0287 - accuracy: 0.9950\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0268 - accuracy: 0.9950\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0251 - accuracy: 0.9950\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0239 - accuracy: 0.9950\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0225 - accuracy: 0.9950\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0213 - accuracy: 0.9962\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0202 - accuracy: 0.9962\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0191 - accuracy: 0.9962\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0209 - accuracy: 0.9950\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0338 - accuracy: 0.9925\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0233 - accuracy: 0.9975\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0183 - accuracy: 0.9975\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0167 - accuracy: 0.9987\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0151 - accuracy: 0.9987\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0144 - accuracy: 0.9987\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0137 - accuracy: 0.9987\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0127 - accuracy: 0.9987\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0119 - accuracy: 0.9987\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0110 - accuracy: 0.9987\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 9.9507e-04 - accuracy: 1.0000\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 9.7722e-04 - accuracy: 1.0000\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 9.6125e-04 - accuracy: 1.0000\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 9.4421e-04 - accuracy: 1.0000\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 9.2789e-04 - accuracy: 1.0000\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 9.1260e-04 - accuracy: 1.0000\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 8.9814e-04 - accuracy: 1.0000\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 8.8239e-04 - accuracy: 1.0000\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 8.6833e-04 - accuracy: 1.0000\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 8.5372e-04 - accuracy: 1.0000\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 8.4029e-04 - accuracy: 1.0000\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 8.2660e-04 - accuracy: 1.0000\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 8.1275e-04 - accuracy: 1.0000\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 7.9972e-04 - accuracy: 1.0000\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 7.8812e-04 - accuracy: 1.0000\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 7.7500e-04 - accuracy: 1.0000\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 7.6297e-04 - accuracy: 1.0000\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 7.5110e-04 - accuracy: 1.0000\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 1s 149ms/step - loss: 7.3981e-04 - accuracy: 1.0000\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 1s 76ms/step - loss: 7.2823e-04 - accuracy: 1.0000\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 7.1720e-04 - accuracy: 1.0000\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 7.0665e-04 - accuracy: 1.0000\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 6.9548e-04 - accuracy: 1.0000\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 6.8465e-04 - accuracy: 1.0000\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 6.7509e-04 - accuracy: 1.0000\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 6.6473e-04 - accuracy: 1.0000\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 6.5519e-04 - accuracy: 1.0000\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 6.4591e-04 - accuracy: 1.0000\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 6.3623e-04 - accuracy: 1.0000\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 6.2678e-04 - accuracy: 1.0000\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 6.1814e-04 - accuracy: 1.0000\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 6.0954e-04 - accuracy: 1.0000\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 6.0044e-04 - accuracy: 1.0000\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.9198e-04 - accuracy: 1.0000\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 5.8384e-04 - accuracy: 1.0000\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 5.7551e-04 - accuracy: 1.0000\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.6773e-04 - accuracy: 1.0000\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 5.5983e-04 - accuracy: 1.0000\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 5.5197e-04 - accuracy: 1.0000\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 5.4467e-04 - accuracy: 1.0000\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.3747e-04 - accuracy: 1.0000\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 5.2977e-04 - accuracy: 1.0000\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.2292e-04 - accuracy: 1.0000\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 5.1601e-04 - accuracy: 1.0000\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 5.0890e-04 - accuracy: 1.0000\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 5.0218e-04 - accuracy: 1.0000\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.9558e-04 - accuracy: 1.0000\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.8918e-04 - accuracy: 1.0000\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.8278e-04 - accuracy: 1.0000\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.7651e-04 - accuracy: 1.0000\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.7022e-04 - accuracy: 1.0000\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.6490e-04 - accuracy: 1.0000\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.5863e-04 - accuracy: 1.0000\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 4.5281e-04 - accuracy: 1.0000\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 4.4718e-04 - accuracy: 1.0000\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 4.4149e-04 - accuracy: 1.0000\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 4.3610e-04 - accuracy: 1.0000\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.3074e-04 - accuracy: 1.0000\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.2532e-04 - accuracy: 1.0000\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.2032e-04 - accuracy: 1.0000\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.1503e-04 - accuracy: 1.0000\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 4.1007e-04 - accuracy: 1.0000\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.0521e-04 - accuracy: 1.0000\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 4.0033e-04 - accuracy: 1.0000\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 3.9535e-04 - accuracy: 1.0000\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.9067e-04 - accuracy: 1.0000\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.8608e-04 - accuracy: 1.0000\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.8164e-04 - accuracy: 1.0000\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.7708e-04 - accuracy: 1.0000\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.7274e-04 - accuracy: 1.0000\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.6822e-04 - accuracy: 1.0000\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.6407e-04 - accuracy: 1.0000\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.5993e-04 - accuracy: 1.0000\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.5581e-04 - accuracy: 1.0000\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.5162e-04 - accuracy: 1.0000\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.4758e-04 - accuracy: 1.0000\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.4389e-04 - accuracy: 1.0000\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.3980e-04 - accuracy: 1.0000\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.3601e-04 - accuracy: 1.0000\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.3212e-04 - accuracy: 1.0000\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.2866e-04 - accuracy: 1.0000\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.2517e-04 - accuracy: 1.0000\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.2128e-04 - accuracy: 1.0000\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.1766e-04 - accuracy: 1.0000\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 3.1435e-04 - accuracy: 1.0000\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 3.1100e-04 - accuracy: 1.0000\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.0747e-04 - accuracy: 1.0000\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.0419e-04 - accuracy: 1.0000\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.0092e-04 - accuracy: 1.0000\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.9763e-04 - accuracy: 1.0000\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.9438e-04 - accuracy: 1.0000\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.9126e-04 - accuracy: 1.0000\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 2.8826e-04 - accuracy: 1.0000\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 2.8509e-04 - accuracy: 1.0000\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 2.8213e-04 - accuracy: 1.0000\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 2.7921e-04 - accuracy: 1.0000\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 2.7621e-04 - accuracy: 1.0000\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.7344e-04 - accuracy: 1.0000\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.7059e-04 - accuracy: 1.0000\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 2.6767e-04 - accuracy: 1.0000\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.6488e-04 - accuracy: 1.0000\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.6226e-04 - accuracy: 1.0000\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.5957e-04 - accuracy: 1.0000\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.5687e-04 - accuracy: 1.0000\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.5427e-04 - accuracy: 1.0000\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.5181e-04 - accuracy: 1.0000\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 2.4918e-04 - accuracy: 1.0000\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.4659e-04 - accuracy: 1.0000\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.4419e-04 - accuracy: 1.0000\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.4172e-04 - accuracy: 1.0000\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.3929e-04 - accuracy: 1.0000\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.3699e-04 - accuracy: 1.0000\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 2.3455e-04 - accuracy: 1.0000\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.3226e-04 - accuracy: 1.0000\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.2991e-04 - accuracy: 1.0000\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.2780e-04 - accuracy: 1.0000\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.2540e-04 - accuracy: 1.0000\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.2335e-04 - accuracy: 1.0000\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.2119e-04 - accuracy: 1.0000\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.1905e-04 - accuracy: 1.0000\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.1687e-04 - accuracy: 1.0000\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.1484e-04 - accuracy: 1.0000\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 2.1274e-04 - accuracy: 1.0000\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 2.1077e-04 - accuracy: 1.0000\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 2.0868e-04 - accuracy: 1.0000\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.0677e-04 - accuracy: 1.0000\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.0473e-04 - accuracy: 1.0000\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.0277e-04 - accuracy: 1.0000\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 2.0094e-04 - accuracy: 1.0000\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.9915e-04 - accuracy: 1.0000\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 1.9715e-04 - accuracy: 1.0000\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.9531e-04 - accuracy: 1.0000\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.9349e-04 - accuracy: 1.0000\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.9173e-04 - accuracy: 1.0000\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.9004e-04 - accuracy: 1.0000\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.8818e-04 - accuracy: 1.0000\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.8647e-04 - accuracy: 1.0000\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.8480e-04 - accuracy: 1.0000\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.8309e-04 - accuracy: 1.0000\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.8145e-04 - accuracy: 1.0000\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.7985e-04 - accuracy: 1.0000\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.7814e-04 - accuracy: 1.0000\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.7653e-04 - accuracy: 1.0000\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.7495e-04 - accuracy: 1.0000\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.7341e-04 - accuracy: 1.0000\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.7187e-04 - accuracy: 1.0000\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.7033e-04 - accuracy: 1.0000\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.6877e-04 - accuracy: 1.0000\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.6732e-04 - accuracy: 1.0000\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.6586e-04 - accuracy: 1.0000\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.6429e-04 - accuracy: 1.0000\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.6290e-04 - accuracy: 1.0000\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.6153e-04 - accuracy: 1.0000\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.6006e-04 - accuracy: 1.0000\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5874e-04 - accuracy: 1.0000\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.5734e-04 - accuracy: 1.0000\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.5589e-04 - accuracy: 1.0000\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5456e-04 - accuracy: 1.0000\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5324e-04 - accuracy: 1.0000\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.5194e-04 - accuracy: 1.0000\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.5059e-04 - accuracy: 1.0000\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.4931e-04 - accuracy: 1.0000\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.4806e-04 - accuracy: 1.0000\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.4678e-04 - accuracy: 1.0000\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.4559e-04 - accuracy: 1.0000\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.4431e-04 - accuracy: 1.0000\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.4304e-04 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMDB"
      ],
      "metadata": {
        "id": "XsGxDCodYDHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds=tf.data.Dataset.from_tensor_slices((\n",
        "            tf.cast(imdb_train.text.values, tf.string),\n",
        "            tf.cast(imdb_train.label.values, tf.int64)\n",
        "        ))"
      ],
      "metadata": {
        "id": "apU4uNQgWznx"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_data=tf.data.Dataset.from_tensor_slices((\n",
        "            tf.cast(imdb_test.text.values, tf.string),\n",
        "            tf.cast(imdb_test.label.values, tf.int64)\n",
        "        ))"
      ],
      "metadata": {
        "id": "9ghXChcsYUtW"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "\n",
        "ds = ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "v_data = v_data.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "gehMRXv5YeUj"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 3300\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(ds.map(lambda text, label: text))\n",
        "\n",
        "vocab = np.array(encoder.get_vocabulary())"
      ],
      "metadata": {
        "id": "xU052VYmYmSV"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=2,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "AJo8UTDeYqN-"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrs1O9gTYs_g",
        "outputId": "cc71a275-ffdd-4917-f7ee-86fc7f3bf5e8"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_10 (Tex  (None, None)              0         \n",
            " tVectorization)                                                 \n",
            "                                                                 \n",
            " embedding_12 (Embedding)    (None, None, 2)           5518      \n",
            "                                                                 \n",
            " bidirectional_12 (Bidirect  (None, 16)                704       \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6367 (24.87 KB)\n",
            "Trainable params: 6367 (24.87 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "61gl2HQPYxgI"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(ds, epochs=300,\n",
        "                    validation_data=v_data,\n",
        "                    validation_steps=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "897ZWsxRY1aN",
        "outputId": "7de2f506-5859-4b1f-e72d-619f0759e480"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "8/8 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f54347bfd00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8/8 [==============================] - 15s 730ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.6930 - accuracy: 0.5000\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6928 - accuracy: 0.5000\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.6926 - accuracy: 0.5000\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.6920 - accuracy: 0.5000\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.6905 - accuracy: 0.5000\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6869 - accuracy: 0.5000\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.6815 - accuracy: 0.5000\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.6723 - accuracy: 0.5000\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.6574 - accuracy: 0.5000\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.6317 - accuracy: 0.5350\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.5918 - accuracy: 0.6212\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.5371 - accuracy: 0.6762\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.4674 - accuracy: 0.7475\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 1s 89ms/step - loss: 0.4001 - accuracy: 0.8112\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.3407 - accuracy: 0.8600\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.2930 - accuracy: 0.8925\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.2477 - accuracy: 0.9137\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.2167 - accuracy: 0.9225\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.1904 - accuracy: 0.9388\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1679 - accuracy: 0.9488\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.1483 - accuracy: 0.9575\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.1323 - accuracy: 0.9688\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.1144 - accuracy: 0.9725\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.1009 - accuracy: 0.9737\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0908 - accuracy: 0.9787\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0821 - accuracy: 0.9812\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0751 - accuracy: 0.9837\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0693 - accuracy: 0.9875\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0833 - accuracy: 0.9887\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0611 - accuracy: 0.9900\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0798 - accuracy: 0.9862\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0609 - accuracy: 0.9887\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0462 - accuracy: 0.9925\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 1s 74ms/step - loss: 0.0545 - accuracy: 0.9912\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 0.0503 - accuracy: 0.9937\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 0.0406 - accuracy: 0.9962\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0369 - accuracy: 0.9962\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0531 - accuracy: 0.9925\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0326 - accuracy: 0.9962\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0316 - accuracy: 0.9987\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0293 - accuracy: 0.9987\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0271 - accuracy: 0.9987\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0255 - accuracy: 0.9987\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0240 - accuracy: 0.9987\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0225 - accuracy: 0.9987\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0212 - accuracy: 0.9987\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0200 - accuracy: 0.9987\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0189 - accuracy: 0.9987\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0179 - accuracy: 0.9987\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0170 - accuracy: 0.9987\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0161 - accuracy: 0.9987\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0154 - accuracy: 0.9987\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0146 - accuracy: 0.9987\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0139 - accuracy: 0.9987\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 0.0133 - accuracy: 0.9987\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 0.0127 - accuracy: 1.0000\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0115 - accuracy: 1.0000\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 1s 142ms/step - loss: 0.0110 - accuracy: 1.0000\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0087 - accuracy: 1.0000\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0195 - accuracy: 0.9987\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0110 - accuracy: 0.9987\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 1s 70ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 1s 62ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 1s 80ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 1s 101ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 9.9146e-04 - accuracy: 1.0000\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 9.7501e-04 - accuracy: 1.0000\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 9.5990e-04 - accuracy: 1.0000\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 9.4467e-04 - accuracy: 1.0000\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 9.3090e-04 - accuracy: 1.0000\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 9.1676e-04 - accuracy: 1.0000\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 9.0368e-04 - accuracy: 1.0000\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 8.8851e-04 - accuracy: 1.0000\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 8.7527e-04 - accuracy: 1.0000\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 8.6296e-04 - accuracy: 1.0000\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 8.5045e-04 - accuracy: 1.0000\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 8.3686e-04 - accuracy: 1.0000\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 8.2502e-04 - accuracy: 1.0000\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 8.1319e-04 - accuracy: 1.0000\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 8.0069e-04 - accuracy: 1.0000\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 7.9075e-04 - accuracy: 1.0000\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 7.7793e-04 - accuracy: 1.0000\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 7.6690e-04 - accuracy: 1.0000\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 7.5632e-04 - accuracy: 1.0000\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 7.4620e-04 - accuracy: 1.0000\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 7.3592e-04 - accuracy: 1.0000\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 7.2513e-04 - accuracy: 1.0000\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 7.1534e-04 - accuracy: 1.0000\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 7.0561e-04 - accuracy: 1.0000\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 6.9604e-04 - accuracy: 1.0000\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 6.8679e-04 - accuracy: 1.0000\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 1s 104ms/step - loss: 6.7784e-04 - accuracy: 1.0000\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 1s 92ms/step - loss: 6.6809e-04 - accuracy: 1.0000\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 6.5947e-04 - accuracy: 1.0000\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 6.5148e-04 - accuracy: 1.0000\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 6.4277e-04 - accuracy: 1.0000\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 6.3412e-04 - accuracy: 1.0000\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 6.2602e-04 - accuracy: 1.0000\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 6.1774e-04 - accuracy: 1.0000\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 6.0984e-04 - accuracy: 1.0000\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 6.0256e-04 - accuracy: 1.0000\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 5.9415e-04 - accuracy: 1.0000\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 5.8741e-04 - accuracy: 1.0000\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 5.7915e-04 - accuracy: 1.0000\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 5.7293e-04 - accuracy: 1.0000\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 5.6547e-04 - accuracy: 1.0000\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 5.5799e-04 - accuracy: 1.0000\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 5.5202e-04 - accuracy: 1.0000\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 5.4455e-04 - accuracy: 1.0000\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 5.3797e-04 - accuracy: 1.0000\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 5.3163e-04 - accuracy: 1.0000\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 5.2488e-04 - accuracy: 1.0000\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 1s 93ms/step - loss: 5.1841e-04 - accuracy: 1.0000\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 5.1224e-04 - accuracy: 1.0000\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 5.0634e-04 - accuracy: 1.0000\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 5.0024e-04 - accuracy: 1.0000\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 4.9452e-04 - accuracy: 1.0000\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 4.8807e-04 - accuracy: 1.0000\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 4.8253e-04 - accuracy: 1.0000\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 4.7711e-04 - accuracy: 1.0000\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 4.7133e-04 - accuracy: 1.0000\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 4.6563e-04 - accuracy: 1.0000\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 4.6031e-04 - accuracy: 1.0000\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 4.5492e-04 - accuracy: 1.0000\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 4.5015e-04 - accuracy: 1.0000\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 4.4432e-04 - accuracy: 1.0000\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 4.3967e-04 - accuracy: 1.0000\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 4.3441e-04 - accuracy: 1.0000\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 4.2947e-04 - accuracy: 1.0000\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 4.2485e-04 - accuracy: 1.0000\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 4.1968e-04 - accuracy: 1.0000\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 4.1516e-04 - accuracy: 1.0000\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 4.1075e-04 - accuracy: 1.0000\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 4.0610e-04 - accuracy: 1.0000\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 4.0144e-04 - accuracy: 1.0000\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 1s 60ms/step - loss: 3.9667e-04 - accuracy: 1.0000\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 3.9269e-04 - accuracy: 1.0000\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 3.8803e-04 - accuracy: 1.0000\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 3.8375e-04 - accuracy: 1.0000\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 3.7996e-04 - accuracy: 1.0000\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 3.7576e-04 - accuracy: 1.0000\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 3.7140e-04 - accuracy: 1.0000\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 3.6774e-04 - accuracy: 1.0000\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 3.6350e-04 - accuracy: 1.0000\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 3.5949e-04 - accuracy: 1.0000\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 3.5575e-04 - accuracy: 1.0000\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 3.5185e-04 - accuracy: 1.0000\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 1s 65ms/step - loss: 3.4800e-04 - accuracy: 1.0000\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 1s 105ms/step - loss: 3.4448e-04 - accuracy: 1.0000\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 3.4088e-04 - accuracy: 1.0000\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 3.3714e-04 - accuracy: 1.0000\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 3.3399e-04 - accuracy: 1.0000\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 1s 90ms/step - loss: 3.3034e-04 - accuracy: 1.0000\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 3.2666e-04 - accuracy: 1.0000\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 3.2325e-04 - accuracy: 1.0000\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 3.1987e-04 - accuracy: 1.0000\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 3.1685e-04 - accuracy: 1.0000\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 3.1344e-04 - accuracy: 1.0000\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 3.0987e-04 - accuracy: 1.0000\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 3.0723e-04 - accuracy: 1.0000\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 3.0387e-04 - accuracy: 1.0000\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 3.0088e-04 - accuracy: 1.0000\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 1s 118ms/step - loss: 2.9767e-04 - accuracy: 1.0000\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 2.9484e-04 - accuracy: 1.0000\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 2.9169e-04 - accuracy: 1.0000\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 2.8891e-04 - accuracy: 1.0000\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 2.8610e-04 - accuracy: 1.0000\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 2.8292e-04 - accuracy: 1.0000\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 2.8010e-04 - accuracy: 1.0000\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 2.7772e-04 - accuracy: 1.0000\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 2.7456e-04 - accuracy: 1.0000\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 2.7205e-04 - accuracy: 1.0000\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 2.6923e-04 - accuracy: 1.0000\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 1s 109ms/step - loss: 2.6686e-04 - accuracy: 1.0000\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 2.6396e-04 - accuracy: 1.0000\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 2.6142e-04 - accuracy: 1.0000\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 2.5878e-04 - accuracy: 1.0000\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 2.5652e-04 - accuracy: 1.0000\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 2.5387e-04 - accuracy: 1.0000\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 2.5140e-04 - accuracy: 1.0000\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 2.4901e-04 - accuracy: 1.0000\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 2.4656e-04 - accuracy: 1.0000\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 2.4448e-04 - accuracy: 1.0000\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 2.4192e-04 - accuracy: 1.0000\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 2.3953e-04 - accuracy: 1.0000\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 2.3725e-04 - accuracy: 1.0000\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 2.3527e-04 - accuracy: 1.0000\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 2.3263e-04 - accuracy: 1.0000\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 2.3086e-04 - accuracy: 1.0000\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 2.2853e-04 - accuracy: 1.0000\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 2.2624e-04 - accuracy: 1.0000\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 2.2418e-04 - accuracy: 1.0000\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 2.2235e-04 - accuracy: 1.0000\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 2.2012e-04 - accuracy: 1.0000\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 2.1807e-04 - accuracy: 1.0000\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 2.1610e-04 - accuracy: 1.0000\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 2.1400e-04 - accuracy: 1.0000\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 2.1221e-04 - accuracy: 1.0000\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 2.1017e-04 - accuracy: 1.0000\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 2.0825e-04 - accuracy: 1.0000\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 2.0654e-04 - accuracy: 1.0000\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 2.0444e-04 - accuracy: 1.0000\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 2.0286e-04 - accuracy: 1.0000\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 2.0085e-04 - accuracy: 1.0000\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.9895e-04 - accuracy: 1.0000\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.9715e-04 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YELP"
      ],
      "metadata": {
        "id": "8454W7_ZZz75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds=tf.data.Dataset.from_tensor_slices((\n",
        "            tf.cast(yelp_train.text.values, tf.string),\n",
        "            tf.cast(yelp_train.label.values, tf.int64)\n",
        "        ))"
      ],
      "metadata": {
        "id": "XUHE9qf-Y4Mc"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_data=tf.data.Dataset.from_tensor_slices((\n",
        "            tf.cast(yelp_test.text.values, tf.string),\n",
        "            tf.cast(yelp_test.label.values, tf.int64)\n",
        "        ))"
      ],
      "metadata": {
        "id": "V3D_wTVdaCS8"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "\n",
        "ds = ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "v_data = v_data.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "GI7aONcwaE_j"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 2000\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(ds.map(lambda text, label: text))\n",
        "\n",
        "vocab = np.array(encoder.get_vocabulary())"
      ],
      "metadata": {
        "id": "uU_1dWCHaHtk"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=2,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(8)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "id": "pbszbxR5aMD6"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGHZFpSFaOtR",
        "outputId": "d6a0d00b-da00-4947-83d0-2f3b84e08443"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization_11 (Tex  (None, None)              0         \n",
            " tVectorization)                                                 \n",
            "                                                                 \n",
            " embedding_13 (Embedding)    (None, None, 2)           3630      \n",
            "                                                                 \n",
            " bidirectional_13 (Bidirect  (None, 16)                704       \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4479 (17.50 KB)\n",
            "Trainable params: 4479 (17.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9WXbvw0caRYP"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(ds, epochs=300,\n",
        "                    validation_data=v_data,\n",
        "                    validation_steps=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9drjyMmaWSp",
        "outputId": "9c7c0339-9d6e-4215-f0d0-dd13aa0fc747"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.6934 - accuracy: 0.5014"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f5433c9c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r8/8 [==============================] - 13s 446ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6926 - accuracy: 0.5000\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6920 - accuracy: 0.5000\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6911 - accuracy: 0.5000\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6899 - accuracy: 0.5000\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6884 - accuracy: 0.5000\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6864 - accuracy: 0.5000\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 0.6836 - accuracy: 0.5000\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.6795 - accuracy: 0.5000\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 0.6743 - accuracy: 0.5000\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.6659 - accuracy: 0.5000\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.6555 - accuracy: 0.5000\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6413 - accuracy: 0.5000\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6233 - accuracy: 0.5000\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6005 - accuracy: 0.5000\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5711 - accuracy: 0.5000\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5365 - accuracy: 0.5000\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4988 - accuracy: 0.5000\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4543 - accuracy: 0.5350\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4088 - accuracy: 0.6338\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.3627 - accuracy: 0.7800\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3186 - accuracy: 0.8662\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.2749 - accuracy: 0.9062\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2310 - accuracy: 0.9388\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 1s 61ms/step - loss: 0.1912 - accuracy: 0.9563\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.1595 - accuracy: 0.9650\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.1347 - accuracy: 0.9725\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.1150 - accuracy: 0.9762\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0980 - accuracy: 0.9800\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0860 - accuracy: 0.9900\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0749 - accuracy: 0.9925\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0661 - accuracy: 0.9937\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0587 - accuracy: 0.9937\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0525 - accuracy: 0.9950\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0472 - accuracy: 0.9950\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0424 - accuracy: 0.9950\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0384 - accuracy: 0.9950\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0345 - accuracy: 0.9950\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0312 - accuracy: 0.9950\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0283 - accuracy: 0.9962\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0258 - accuracy: 0.9987\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0235 - accuracy: 0.9987\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0214 - accuracy: 0.9987\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0196 - accuracy: 0.9987\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0181 - accuracy: 0.9987\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0166 - accuracy: 0.9987\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0153 - accuracy: 0.9987\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 0.0142 - accuracy: 0.9987\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 1s 66ms/step - loss: 0.0131 - accuracy: 0.9987\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 0.0123 - accuracy: 0.9987\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.0113 - accuracy: 0.9987\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0105 - accuracy: 0.9987\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0098 - accuracy: 0.9987\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0079 - accuracy: 1.0000\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0231 - accuracy: 0.9950\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0116 - accuracy: 0.9975\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0093 - accuracy: 0.9987\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 9.9611e-04 - accuracy: 1.0000\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 9.7474e-04 - accuracy: 1.0000\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 9.5304e-04 - accuracy: 1.0000\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 9.3240e-04 - accuracy: 1.0000\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 9.1227e-04 - accuracy: 1.0000\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 8.9264e-04 - accuracy: 1.0000\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 8.7190e-04 - accuracy: 1.0000\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 8.5443e-04 - accuracy: 1.0000\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 8.3832e-04 - accuracy: 1.0000\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 8.1872e-04 - accuracy: 1.0000\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 8.0403e-04 - accuracy: 1.0000\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 7.8657e-04 - accuracy: 1.0000\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 7.7071e-04 - accuracy: 1.0000\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 7.5507e-04 - accuracy: 1.0000\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 7.4052e-04 - accuracy: 1.0000\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 7.2659e-04 - accuracy: 1.0000\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 7.1260e-04 - accuracy: 1.0000\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 6.9774e-04 - accuracy: 1.0000\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 6.8548e-04 - accuracy: 1.0000\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 6.7209e-04 - accuracy: 1.0000\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 6.5913e-04 - accuracy: 1.0000\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 6.4653e-04 - accuracy: 1.0000\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 6.3536e-04 - accuracy: 1.0000\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 6.2358e-04 - accuracy: 1.0000\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 6.1228e-04 - accuracy: 1.0000\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 6.0078e-04 - accuracy: 1.0000\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 5.9023e-04 - accuracy: 1.0000\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 5.7974e-04 - accuracy: 1.0000\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 5.6944e-04 - accuracy: 1.0000\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 5.5984e-04 - accuracy: 1.0000\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 5.5005e-04 - accuracy: 1.0000\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 5.4014e-04 - accuracy: 1.0000\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 5.3139e-04 - accuracy: 1.0000\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 5.2201e-04 - accuracy: 1.0000\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 5.1360e-04 - accuracy: 1.0000\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 5.0463e-04 - accuracy: 1.0000\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.9643e-04 - accuracy: 1.0000\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.8822e-04 - accuracy: 1.0000\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.8037e-04 - accuracy: 1.0000\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.7179e-04 - accuracy: 1.0000\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.6437e-04 - accuracy: 1.0000\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 4.5779e-04 - accuracy: 1.0000\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.4941e-04 - accuracy: 1.0000\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.4315e-04 - accuracy: 1.0000\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 4.3562e-04 - accuracy: 1.0000\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 4.2885e-04 - accuracy: 1.0000\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 4.2225e-04 - accuracy: 1.0000\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.1565e-04 - accuracy: 1.0000\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 4.0928e-04 - accuracy: 1.0000\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 4.0305e-04 - accuracy: 1.0000\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 3.9700e-04 - accuracy: 1.0000\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 3.9085e-04 - accuracy: 1.0000\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 3.8494e-04 - accuracy: 1.0000\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 0s 61ms/step - loss: 3.7959e-04 - accuracy: 1.0000\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 3.7345e-04 - accuracy: 1.0000\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 3.6858e-04 - accuracy: 1.0000\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.6239e-04 - accuracy: 1.0000\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.5767e-04 - accuracy: 1.0000\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 3.5215e-04 - accuracy: 1.0000\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.4733e-04 - accuracy: 1.0000\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.4218e-04 - accuracy: 1.0000\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 3.3749e-04 - accuracy: 1.0000\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 3.3251e-04 - accuracy: 1.0000\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.2801e-04 - accuracy: 1.0000\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 3.2326e-04 - accuracy: 1.0000\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 3.1923e-04 - accuracy: 1.0000\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 3.1425e-04 - accuracy: 1.0000\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 3.1005e-04 - accuracy: 1.0000\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 3.0627e-04 - accuracy: 1.0000\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 3.0171e-04 - accuracy: 1.0000\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.9777e-04 - accuracy: 1.0000\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 2.9351e-04 - accuracy: 1.0000\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.8967e-04 - accuracy: 1.0000\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.8596e-04 - accuracy: 1.0000\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.8201e-04 - accuracy: 1.0000\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 2.7830e-04 - accuracy: 1.0000\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.7492e-04 - accuracy: 1.0000\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.7118e-04 - accuracy: 1.0000\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.6774e-04 - accuracy: 1.0000\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 2.6413e-04 - accuracy: 1.0000\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.6078e-04 - accuracy: 1.0000\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.5751e-04 - accuracy: 1.0000\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 2.5420e-04 - accuracy: 1.0000\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 2.5105e-04 - accuracy: 1.0000\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.4785e-04 - accuracy: 1.0000\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.4467e-04 - accuracy: 1.0000\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 2.4163e-04 - accuracy: 1.0000\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.3870e-04 - accuracy: 1.0000\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 2.3586e-04 - accuracy: 1.0000\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 2.3291e-04 - accuracy: 1.0000\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 2.3011e-04 - accuracy: 1.0000\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 2.2734e-04 - accuracy: 1.0000\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 0s 58ms/step - loss: 2.2443e-04 - accuracy: 1.0000\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.2179e-04 - accuracy: 1.0000\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 2.1910e-04 - accuracy: 1.0000\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.1648e-04 - accuracy: 1.0000\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 2.1394e-04 - accuracy: 1.0000\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.1153e-04 - accuracy: 1.0000\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.0874e-04 - accuracy: 1.0000\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 2.0644e-04 - accuracy: 1.0000\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.0409e-04 - accuracy: 1.0000\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 2.0166e-04 - accuracy: 1.0000\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.9947e-04 - accuracy: 1.0000\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.9702e-04 - accuracy: 1.0000\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.9472e-04 - accuracy: 1.0000\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.9259e-04 - accuracy: 1.0000\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.9041e-04 - accuracy: 1.0000\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.8818e-04 - accuracy: 1.0000\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.8613e-04 - accuracy: 1.0000\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.8403e-04 - accuracy: 1.0000\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.8195e-04 - accuracy: 1.0000\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.8001e-04 - accuracy: 1.0000\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.7800e-04 - accuracy: 1.0000\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.7596e-04 - accuracy: 1.0000\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.7413e-04 - accuracy: 1.0000\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.7214e-04 - accuracy: 1.0000\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.7033e-04 - accuracy: 1.0000\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.6853e-04 - accuracy: 1.0000\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.6660e-04 - accuracy: 1.0000\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.6489e-04 - accuracy: 1.0000\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.6307e-04 - accuracy: 1.0000\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.6132e-04 - accuracy: 1.0000\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5978e-04 - accuracy: 1.0000\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.5799e-04 - accuracy: 1.0000\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.5632e-04 - accuracy: 1.0000\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.5460e-04 - accuracy: 1.0000\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5315e-04 - accuracy: 1.0000\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.5146e-04 - accuracy: 1.0000\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.4993e-04 - accuracy: 1.0000\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4826e-04 - accuracy: 1.0000\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 0s 59ms/step - loss: 1.4680e-04 - accuracy: 1.0000\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 1.4529e-04 - accuracy: 1.0000\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.4384e-04 - accuracy: 1.0000\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.4237e-04 - accuracy: 1.0000\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.4088e-04 - accuracy: 1.0000\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.3952e-04 - accuracy: 1.0000\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.3811e-04 - accuracy: 1.0000\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.3670e-04 - accuracy: 1.0000\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.3529e-04 - accuracy: 1.0000\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.3405e-04 - accuracy: 1.0000\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.3255e-04 - accuracy: 1.0000\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.3133e-04 - accuracy: 1.0000\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3007e-04 - accuracy: 1.0000\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.2873e-04 - accuracy: 1.0000\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.2747e-04 - accuracy: 1.0000\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.2627e-04 - accuracy: 1.0000\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.2502e-04 - accuracy: 1.0000\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.2375e-04 - accuracy: 1.0000\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.2260e-04 - accuracy: 1.0000\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.2136e-04 - accuracy: 1.0000\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.2027e-04 - accuracy: 1.0000\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1903e-04 - accuracy: 1.0000\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.1794e-04 - accuracy: 1.0000\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.1685e-04 - accuracy: 1.0000\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.1568e-04 - accuracy: 1.0000\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.1462e-04 - accuracy: 1.0000\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.1353e-04 - accuracy: 1.0000\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.1247e-04 - accuracy: 1.0000\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.1136e-04 - accuracy: 1.0000\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.1036e-04 - accuracy: 1.0000\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.0930e-04 - accuracy: 1.0000\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.0832e-04 - accuracy: 1.0000\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.0722e-04 - accuracy: 1.0000\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.0621e-04 - accuracy: 1.0000\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.0524e-04 - accuracy: 1.0000\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.0429e-04 - accuracy: 1.0000\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.0331e-04 - accuracy: 1.0000\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 1.0240e-04 - accuracy: 1.0000\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 1.0143e-04 - accuracy: 1.0000\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 1.0056e-04 - accuracy: 1.0000\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 9.9651e-05 - accuracy: 1.0000\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 9.8764e-05 - accuracy: 1.0000\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 9.7821e-05 - accuracy: 1.0000\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 9.7010e-05 - accuracy: 1.0000\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 9.6034e-05 - accuracy: 1.0000\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 9.5267e-05 - accuracy: 1.0000\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 9.4427e-05 - accuracy: 1.0000\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 9.3578e-05 - accuracy: 1.0000\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 9.2797e-05 - accuracy: 1.0000\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 9.1924e-05 - accuracy: 1.0000\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 9.1132e-05 - accuracy: 1.0000\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 9.0323e-05 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v2qQ_1zLaZDD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}